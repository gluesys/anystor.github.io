---
layout:     post
title:      "자 따라해봐요 이렇게~ 그래, 한번 해보자 SPDK 실습"
date:       2022-02-17
author:     김 태훈 (thkim@gluesys.com)
categories: blog
tags:       [SPDK, NVMe, SSD, Flash, Memory, RDMA, Storage]
cover:      "/assets/SPDK_maincover.jpg"
main:       "/assets/SPDK_maincover.jpg"
---

안녕하세요. 오늘은 SPDK의 최신 코드를 이용해서 테스트 환경을 구축해보고 SPDK의 일부 기능을 실습하도록 하겠습니다.

&nbsp;

## SPDK 간단한 설명

지난 [포스팅](https://tech.gluesys.com/blog/2022/02/18/SPDK_1.html)에서 소개한 바와 같이 SPDK는 기존에 정통적인 커널 계층의 블록 드라이버 레이어를 걷어내고 사용자 공간(userspace) 계층에서 드라이버를 구현하여 NVMe와 같은 초고속 SSD 장치를 효율적으로 사용하기 위한 프레임워크입니다. SPDK 코드에는 NVMe 장치에 기본적인 기능(open, read, write, close 등)을 수행하는 드라이버와 개념의 코드들과, 드라이버를 이용하여 기존 커널에서 제공하던 블록 장치 기술(인터페이스, 논리 볼륨, 큐 배치, 스케줄러 등)의 코드들로 구성됩니다. SPDK에서는 이러한 기능들을 'bdev' 이라고 표현합니다.

[블록 계층 관련 그림 추가, 출처 표기]
SPDK의 bdev는 기존 커널의 장치 드라이버보다 상위 계층에서 동작하는 블록 계층과 동일한 역할을 수행하는 C 라이브러리 입니다. 블록 계층은 저장 장치를 이용하여 스토리지의 기본 기능들을 제공하는 영역인데, 대표적으로 논리 볼륨과 소프트웨어 RAID, 압축/중복 제거 등이 있습니다. SPDK는 기존 커널에서 제공하는 스토리지 기능들을 일부 제공하고 있으며, 이러한 플러그인 형태의 구현된 기능들을 bdev module로 표현합니다. 현재 bdev module에서 제공하는 기능은 다음과 같습니다.
  * Ceph RBD(RADOS Block Device)
  * Thin Provisioning
  * Device Crypto
  * Throughput Delay
  * GPT(for GUID partition table) & Partitioning
  * iSCSI Initiator (binding LUN to bdev)
  * Open CAS Framework(OCF)
  * Malloc(ramdisk)
  * Null(Similar to '/dev/null')
  * NVMe Device
  * Logical Volume
  * Passthrough
  * Pmem
  * S/W RAID
  * Split
  * Uring
  * Virtio-Block & Virtio-SCSI using vhost
익숙한 기능들도, 처음 보는 단어들이 보이네요. 모듈들의 자세한 설명은 [링크](https://spdk.io/doc/bdev.html)에서 확인하실 수 있습니다. 이외에도 개발자는 SPDK에서 제공하는 bdev 라이브러리([bdev.h](https://spdk.io/doc/bdev_8h.html))를 이용하여 스토리지 기능을 유저 레벨에서 구현할 수 있습니다. 물론 이를 위해서는 관련 기술을 잘 알고 있어야 합니다. 오늘은 우리에게~~제가~~ 익숙한 몇몇 모듈들을 사용해 보도록 하겠습니다

  &nbsp;

## SPDK 설치

먼저 SPDK 깃허브에서 master 브랜치의 최신 코드를 테스트 장비로 가져옵니다.

  ```
  [root@localhost ~]# git clone https://github.com/spdk/spdk
  [root@localhost ~]# cd spdk
  ```

그리고 설치할 코드의 의존성 패키지를 설치합니다.

  ```
  [root@localhost spdk]# scripts/pkgdep.sh --all
  ```

패키지 설치가 완료되면 빌드를 해줍니다. 이때 `./configure` 스크립트를 실행하는데, 어떤 기능들을 활성할지 옵션으로 입력해야 합니다. 먼저 기본값으로 진행합니다.

  ```
  [root@localhost spdk]# ./configure
  [root@localhost spdk]# make -j 40
  ```

빌드가 완료되면 SPDK 드라이버를 사용할 수 있도록 커널에서 소유하고있는 NVMe 장치를 연결 해제해야 합니다. 커널은 운영체제가 부팅되면서 하드웨어 장치들을 인식하고 관련된 드라이버를 실행하여 장치를 사용할 수 있도록 준비합니다. 이때 로드된 드라이버에서 장치에 대한 오너쉽을 해제해야 SPDK에서 장치의 오너쉽을 가져올 수 있습니다.
현재 테스트 장비에는 인텔의 280GB NVMe SSD가 설치되어 있습니다. 해당 장치를 SPDK에서 사용할 수 있도록 준비해보겠습니다.

  ```
  [root@localhost spdk]# nvme list
  Node             SN                   Model                                    Namespace Usage                      Format           FW Rev
  ---------------- -------------------- ---------------------------------------- --------- -------------------------- ---------------- --------
  /dev/nvme0n1     PHMB7435004J280CGN   INTEL SSDPED1D280GA                      1         280.07  GB / 280.07  GB    512   B +  0 B   E2010325
  [root@localhost spdk]# lsblk | grep nvme
  nvme0n1 259:0    0 260.9G  0 disk
  [root@localhost spdk]# scripts/setup.sh
  0000:80:04.2 (8086 2021): Already using the uio_pci_generic driver
  0000:80:04.3 (8086 2021): Already using the uio_pci_generic driver
  0000:80:04.0 (8086 2021): Already using the uio_pci_generic driver
  0000:80:04.1 (8086 2021): Already using the uio_pci_generic driver
  0000:80:04.6 (8086 2021): Already using the uio_pci_generic driver
  0000:80:04.7 (8086 2021): Already using the uio_pci_generic driver
  0000:80:04.4 (8086 2021): Already using the uio_pci_generic driver
  0000:80:04.5 (8086 2021): Already using the uio_pci_generic driver
  0000:00:04.2 (8086 2021): Already using the uio_pci_generic driver
  0000:00:04.3 (8086 2021): Already using the uio_pci_generic driver
  0000:00:04.0 (8086 2021): Already using the uio_pci_generic driver
  0000:00:04.1 (8086 2021): Already using the uio_pci_generic driver
  0000:00:04.6 (8086 2021): Already using the uio_pci_generic driver
  0000:00:04.7 (8086 2021): Already using the uio_pci_generic driver
  0000:00:04.4 (8086 2021): Already using the uio_pci_generic driver
  0000:00:04.5 (8086 2021): Already using the uio_pci_generic driver
  0000:3b:00.0 (8086 2700): nvme -> uio_pci_generic
  ```

드라이버 해제가 완료되었습니다. 다시 조회해볼까요?

  ```
  [root@localhost spdk]# nvme list
  [root@localhost spdk]# lsblk | grep nvme
  ```

결과가 나오지 않습니다. 커널의 관련 드라이버에서 장치의 오너쉽을 해제했기 때문입니다. 관련 기술로 vfio[^1] 또는 uio[^2] 기술을 이용하는데, 자세한 설명은 본 포스팅의 목적과 다르니 이 부분은 향후 심화 과정으로 다뤄보겠습니다. 간단한 내용은 [링크](https://spdk.io/doc/concepts.html)를 참고하시면 되겠습니다. SPDK 테스트가 끝나고 다시 커널에 오너쉽을 넘기려면 `reset` 옵션을 추가하면 됩니다.

  ```
  [root@localhost spdk]# scripts/setup.sh reset
  0000:3b:00.0 (8086 2700): uio_pci_generic -> nvme
  0000:80:04.2 (8086 2021): uio_pci_generic -> no driver
  0000:80:04.3 (8086 2021): uio_pci_generic -> no driver
  0000:80:04.0 (8086 2021): uio_pci_generic -> no driver
  0000:80:04.1 (8086 2021): uio_pci_generic -> no driver
  0000:80:04.6 (8086 2021): uio_pci_generic -> no driver
  0000:80:04.7 (8086 2021): uio_pci_generic -> no driver
  0000:80:04.4 (8086 2021): uio_pci_generic -> no driver
  0000:80:04.5 (8086 2021): uio_pci_generic -> no driver
  0000:00:04.2 (8086 2021): uio_pci_generic -> no driver
  0000:00:04.3 (8086 2021): uio_pci_generic -> no driver
  0000:00:04.0 (8086 2021): uio_pci_generic -> no driver
  0000:00:04.1 (8086 2021): uio_pci_generic -> no driver
  0000:00:04.6 (8086 2021): uio_pci_generic -> no driver
  0000:00:04.7 (8086 2021): uio_pci_generic -> no driver
  0000:00:04.4 (8086 2021): uio_pci_generic -> no driver
  0000:00:04.5 (8086 2021): uio_pci_generic -> no driver
  [root@localhost spdk]# lsblk | grep nvme
  nvme0n1 259:0    0 260.9G  0 disk
  ```

오너쉽이 커널로 넘어갔네요. 간단한 예제를 수행해 보겠습니다.`build/exmpales/hello_world`를 수행합니다.

  ```
  [root@localhost spdk]# build/examples/hello_world
  [2022-01-13 03:44:04.916653] Starting SPDK v22.01-pre git sha1 ed8be4ad0 / DPDK 21.08.0 initialization...
  [2022-01-13 03:44:04.916839] [ DPDK EAL parameters: [2022-01-13 03:44:04.916872] hello_world [2022-01-13 03:44:04.916896] -c 0x1 [2022-01-13 03:44:04.916919] --log-level=lib.eal:6 [2022-01-13 03:44:04.916942] --log-level=lib.cryptodev:5 [2022-01-13 03:44:04.916986] --log-level=user1:6 [2022-01-13 03:44:04.917014] --iova-mode=pa [2022-01-13 03:44:04.917040] --base-virtaddr=0x200000000000 [2022-01-13 03:44:04.917062] --match-allocations [2022-01-13 03:44:04.917086] --file-prefix=spdk0 [2022-01-13 03:44:04.917111] --proc-type=auto [2022-01-13 03:44:04.917133] ]
  EAL: No available 1048576 kB hugepages reported
  EAL: No free 2048 kB hugepages reported on node 1
  TELEMETRY: No legacy callbacks, legacy socket not created
  Initializing NVMe Controllers
  Attaching to 0000:3b:00.0
  Attached to 0000:3b:00.0
  Using controller INTEL SSDPED1D280GA  (PHMB7435004J280CGN  ) with 1 namespaces.
    Namespace ID: 1 size: 280GB
    Initialization complete.
    INFO: using host memory buffer for IO
    Hello world!
  ```

아 좋습니다. 커널의 드라이버와 연결 해제한 NVMe 장치를 SPDK에서 직접 통신하여 SSD의 컨트롤러 정보를 불러왔군요. 이렇게 커널의 드라이버 없이 SPDK를 통해 장치와 통신하는 예제를 실행해봤습니다. 예제의 코드는 `examples/nvme/hello_world/hello_world.c`에서 확인할 수 있습니다.

  * 참고
    - https://spdk.io/doc/getting_started.html

&nbsp;

## SPDK 실습

SPDK 에서 기본적으로 제공하는 기능들은 모두 rpc[^3]로 통신하며, 요청과 응답은 JSON 포맷을 사용합니다. 따라서 rpc 통신을 위해서는 소켓을 오픈해야 합니다. 이는 기존 커널에서 시스템 콜을 통해 장치 드라이버에 사용자 명령을 전달하는 것과 같은 구조입니다. 옆 동료가 쿠쿠다스를 부수고 있군요. 더 깊게 들어가지 말고 나중에 다루겠습니다. 필요하신 분들은 [링크1](https://spdk.io/doc/app_overview.html) [링크2](https://spdk.io/doc/jsonrpc.html)를 참고하세요!
일단 rpc 통신을 위해 소켓을 생성해야 합니다. 동작 여부를 확인하기 위해 소켓 프로세스는 포그라운드로 실행하겠습니다. 별도의 터미널을 띄우고 `build/bin/spdk_tgt`를 실행합니다. [참고](https://github.com/spdk/spdk/issues/295)
TODO : spdk_tgt에 대한 설명 추가

  * 새로운 터미널에서 수행

  ```
  [root@localhost spdk]# build/bin/spdk_tgt
  [2022-01-13 03:09:42.140847] Starting SPDK v22.01-pre git sha1 ed8be4ad0 / DPDK 21.08.0 initialization...
  [2022-01-13 03:09:42.141026] [ DPDK EAL parameters: [2022-01-13 03:09:42.141060] spdk_tgt [2022-01-13 03:09:42.141086] --no-shconf [2022-01-13 03:09:42.141108] -c 0x1 [2022-01-13 03:09:42.141142] --log-level=lib.eal:6 [2022-01-13 03:09:42.141189] --log-level=lib.cryptodev:5 [2022-01-13 03:09:42.141217] --log-level=user1:6 [2022-01-13 03:09:42.141241] --iova-mode=pa [2022-01-13 03:09:42.141265] --base-virtaddr=0x200000000000 [2022-01-13 03:09:42.141293] --match-allocations [2022-01-13 03:09:42.141316] --file-prefix=spdk_pid9976 [2022-01-13 03:09:42.141339] ]
  EAL: No available 1048576 kB hugepages reported
  EAL: No free 2048 kB hugepages reported on node 1
  TELEMETRY: No legacy callbacks, legacy socket not created
  [2022-01-13 03:09:42.223467] app.c: 543:spdk_app_start: *NOTICE*: Total cores available: 1
  [2022-01-13 03:09:42.354606] reactor.c: 943:reactor_run: *NOTICE*: Reactor started on core 0
  [2022-01-13 03:09:42.354674] accel_engine.c:1012:spdk_accel_engine_initialize: *NOTICE*: Accel engine initialized to use software engine.
  ```

이어서 `spdk_tgt`를 수행한 터미널이 아닌 다른 터미널에서 소켓이 생성되었는지 확인합니다. 모두 아시다시피 리눅스는 프로세스간의 통신을 파일 형태의 소켓으로 관리합니다. spdk의 rpc를 위한 소켓 파일은 `/var/tmp/spdk.sock`에서 확인할 수 있습니다.

  ```
  [root@localhost spdk]# ls -l /var/tmp/spdk.sock
  srwxr-xr-x 1 root root 0 Apr  8 19:36 /var/tmp/spdk.sock
  [root@localhost spdk]# lsof -U | grep 'spdk.sock'
  reactor_0  49063           root  373u  unix 0xffff9a31531df2c0      0t0 656974096 /var/tmp/spdk.sock
  [root@localhost spdk]# file /var/tmp/spdk.sock
  /var/tmp/spdk.sock: socket
  ```

  * 참고
    - https://spdk.io/doc/bdev.html
    - https://github.com/spdk/spdk/issues/295

### NVMe 컨트롤러 등록

자, SPDK 실습을 위한 환경 구성이 완료되었습니다. 지금부터는 SPDK에서 제공하는 bdev 목록에서 몇 개의 기능을 사용해보도록 하겠습니다. 먼저 SPDK에서 NVMe SSD의 컨트롤러 정보를 불러오는 방법입니다. 일반적으로 리눅스에서 NVMe SSD를 제어할 때 `nvme` 명령을 사용합니다. `nvme` 명령은 NVMe github의 nvme-cli 코드로 관리되며 NVMe의 최신 스펙에 맞춰서 기속적으로 개발되고 있습니다. `nvme` 명령으로는 NVMe SSD의 다양한 설정을 수행할 수 있습니다. 2019년도 당시, 국제 스토리지 성능 평가를 수행하는 SPC 협회의 SPC-1 성능 테스트를 수행할 때 `nvme` 명령으로 삼성과 인텔 NVMe SSD의 성능 최적화를 수행했었습니다(~~[당시 세계 성능 5위](https://www.etnews.com/20190102000138), 깨알 자랑~~). 그만큼 `nvme` 명령은 NVMe SSD에 강력한 기능을 제공합니다만, SPDK로 오너쉽을 넘긴 이상 `nvme` 명령으로 더이상 NVMe SSD를 제어할 수 없습니다. 띄옹??? 한번 확인해볼까요?

  ```
  [root@localhost spdk]# nvme list
  <no output message>
  ```

홀리 x, 그러면 NVMe SSD의 컨트롤러 정보를 불러오지 못하는가? 아닙니다. NVMe SSD 제조사는 NVM Express 협회에서 제공하는 표준 스펙을 따라야 합니다. 물론 과거에도 FusionIO 와 같은 낸드 플래시와 PCIe 인터페이스를 접목한 PCIe SSD(유사 NVMe) 제품들이 있었습니다. 다만, 워낙 고가였고 제조사마다 서로 다른 스펙으로 개발되었기 때문에 일반 PC급 시장보다 서버시장에서 주로 사용되었습니다. 당시 PCIe SSD 는 별다른 표준이 없었기에 제조사마다 서로 다른 스펙을 가졌었고, 대부분의 기술이 공개되지 않아 소프트웨어 계층에서는 적극적인 활용이 어려웠습니다. 이러한 문제가 직면되어 다른 진영에서는 표준화 작업을 진행하였고, 인텔이 주도한 PCIe SSD 표준화 협회가 NVM Express, 여기서 등장한 표준이 NVMe & NVMe-oF specification 입니다. (짝짝짝!!)
    
음... 잠깐 샛길로 빠졌군요. 다시 돌아와서! 어쨌던 공개된 NVMe 스펙을 통해서 SPDK에서도 `nvme` 명령과 유사한 작업을 수행할 수 있습니다. 한번 볼까요? 먼저 `spdk_tgt`이 동작하고 있어야 하며, `spdk_tgt`이 수행되지 않은 다른 터미널에서 아래 명령을 수행합니다. 먼저 현재 장비에 설치되어 있는 NVMe SSD 장치의 PCIe 번홀를 확인합니다.

  ```
  [root@localhost spdk]# lspci | grep -i ssd
  3b:00.0 Non-Volatile memory controller: Intel Corporation Optane SSD 900P Series
  ```

아 좋습니다. 인텔의 Optane SSD 900P 시리즈 제품이 확인되네요. 연구소에 이런 제품들이 사무용 마우스보다 훨씬 많습니다. (현재 120만원, 출시 당시 가격 ㅎㄷㄷ) `3b:00.0`을 확인했으니 컨트롤러를 SPDK에 연결해봅니다. 이때, RPC 통신을 위해서 모든 작업은 `scripts/rpc.py`로 수행되어야 합니다. 실행할 작업은 `bdev_nvme_attach_controller` 입니다. 연결할 컨트롤러의 이름은 `NVMe`, 연결 방식은 `pcie`로 하겠습니다.

  ```
  [root@localhost spdk]# scripts/rpc.py bdev_nvme_attach_controller -b NVMe0 -t pcie -a 0000:3b:00.0
  NVMe0n1
  ```

오 뭔가 명령이 잘 수행된 느낌입니다. SPDK에 연결된 컨트롤러 정보를 불러오겠습니다.

  ```
  [root@localhost spdk]# scripts/rpc.py bdev_nvme_get_controllers
  [
    {
      "name": "NVMe0",
      "trid": {
        "trtype": "PCIe",
        "traddr": "0000:3b:00.0"
      },
      "host": {
        "nqn": "nqn.2014-08.org.nvmexpress:uuid:2b4d86b5-b34a-4983-9830-2978727acb4a",
        "addr": "",
        "svcid": ""
      }
    }
  ]
  ```

짝짝짝. 잘 연결되어 있습니다. 좋습니다. 반대로 연결을 해제하고 싶으면 `bdev_nvme_detach_controller`를 실행하시면 됩니다.

  ```
  [root@localhost spdk]# scripts/rpc.py bdev_nvme_detach_controller NVMe0
  [root@localhost spdk]# scripts/rpc.py bdev_nvme_get_controllers
  []
  ```

이외에도 현재 SPDK에서 제공하는 nvme와 관련된 여러 기능들을 사용할 수 있습니다.

  ```
  [root@localhost spdk]# # scripts/rpc.py | grep nvme
      bdev_nvme_set_options (set_bdev_nvme_options)
                            Set options for the bdev nvme type. This is startup
      bdev_nvme_set_hotplug (set_bdev_nvme_hotplug)
                            Set hotplug options for bdev nvme type.
      bdev_nvme_attach_controller (construct_nvme_bdev)
                            Add bdevs with nvme backend
      bdev_nvme_get_controllers (get_nvme_controllers)
      bdev_nvme_detach_controller (delete_nvme_controller)
      bdev_nvme_reset_controller
      bdev_nvme_cuse_register
      bdev_nvme_cuse_unregister
      bdev_nvme_apply_firmware (apply_firmware)
      bdev_nvme_get_transport_statistics
                            Get bdev_nvme poll group transport statistics
      bdev_nvme_get_controller_health_info
      bdev_nvme_opal_init
      bdev_nvme_opal_revert
      bdev_nvme_send_cmd (send_nvme_cmd)
  ```

OK 좋습니다. 그런데 최적화 같은 제조사가 제공하는 컨트롤러의 여러 기능들을 변경하고 싶은데, SPDK로 등록하면 어떻게 제어해야하나? 방법이 있습니다. 먼저 PCIe configuration register format(아래 그림1)을 보시고, BAR(Base Address Registers)에 등록된 NVMe controller register format(아래 그림2)을 확인한 다음에, 얻으려는 정보가 맵핑된 메모리의 위치를 찾아서 `bdev_nvme_send_cmd` 기능을 사용해서 NVMe 컨트롤러에 명령을 보내면 알려줍니다.

![Alt text](/assets/pci_header.png) 참고 : NVMe Spec. version 1.4b document
<center>그림 1. PCIe configuration register format</center>

![Alt text](/assets/nvme_register.png)
<center>그림 2. NVMe controller register format</center>

점점 깊어지고 실습하기 싫어지네요. 하드웨어 잘 아는 개발자들이 친절하게 NVMe 스펙 참고해서 일반인이 편히 사용하기 위해서(~~자기들도 편하려고..~~) nvme-cli를 만들었는데, 그걸 사용하지 못하니까 답답합니다. 다행히도 SPDK에서는 `nvme` 명령처럼 기존 명령이나 또는 어플리케이션에서 장치와 직접 통신할 수 있는 방법을 제공합니다. 바로 문자 드라이버 등록입니다.

### 문자 드라이버 등록

우리가 컴퓨터에 장치를 연결하면 리눅스 커널은 장치를 인식해서 알맞은 드라이버를 호출합니다. 리눅스에서 관리하는 디바이스 드라이버는 문자, 블록, 네트워크 종류로 구분됩니다. 이중에서 문자 드라이버는 장치를 파일로 추상화하여 쉽게 접근할 수 있으며, 스트림 방식의 데이터 전송을 수행합니다.(문자 드라이버 외에 블록과 네트워크 드라이버에 대한 자세한 설명은 [여기](https://pages.cs.wisc.edu/~kadav/study/study.pdf)를 참고하시면 좋겠습니다.) 대표적으로 시스템-콜 ioctl은 스트림 방식으로 장치를 제어할 수 있는 기능입니다. `nvme` 명령도 내부적으로 대부분의 제어를 ioctl를 통해 수행합니다. 하지만, SPDK에서 등록한 장치의 오너쉽은 커널이 아니기 때문에 일반적인 방법으로 다룰 수 없습니다. SPDK는 cuse[^4] 라이브러리를 이용하여 SPDK의 유저 공간의 기능을 문자 드라이버로 제공합니다.
이를 위해서는 테스트 서버에 cuse 패키지를 설치해야 합니다. 따라서 초기에 SPDK 환경 구성을 위해 ./configure 명령을 수행할 때, `--with-nvme-cuse` 옵션을 추가하고 리빌드를 수행해야 합니다. 먼저 `spdk_tgt`를 Ctrl+C로 종료합니다.

  ```
  [2022-04-08 20:11:48.864407] bdev_nvme_rpc.c: 400:rpc_bdev_nvme_attach_controller: *ERROR*: The multipath parameter was not specified to bdev_nvme_attach_controller but it was used to add a failover path. This behavior will default to rejecting the request in the future. Specify the 'multipath' parameter to control the behavior[2022-04-08 20:27:33.714712] bdev_nvme.c:3620:bdev_nvme_delete: *ERROR*: Failed to find NVMe bdev controller
  ^C
  [root@localhost spdk]# 
  [root@localhost spdk]# ./configure --with-nvme-cuse
  Notice: ISA-L, compression & crypto require NASM version 2.14 or newer. Turning off default ISA-L and crypto features.
  Using default SPDK env in /root/spdk/lib/env_dpdk
  Using default DPDK in /root/spdk/dpdk/build
  Creating mk/config.mk...done.
  Creating mk/cc.flags.mk...done.
  Type 'make' to build.
  [root@localhost spdk]# make -j 40
  ... <Done>
  [root@localhost spdk]# modprobe cuse
  [root@localhost spdk]# lsmod | grep cuse
  cuse                   13274  0
  fuse                  100350  4 cuse
  [root@localhost spdk]# ./build/bin/spdk_tgt
  [2022-04-08 22:41:44.436670] Starting SPDK v22.01-pre git sha1 ed8be4ad0 / DPDK 21.08.0 initialization...
  [2022-04-08 22:41:44.436857] [ DPDK EAL parameters: [2022-04-08 22:41:44.436891] spdk_tgt [2022-04-08 22:41:44.436919] --no-shconf [2022-04-08 22:41:44.436945] -c 0x1 [2022-04-08 22:41:44.436969] --log-level=lib.eal:6 [2022-04-08 22:41:44.436995] --log-level=lib.cryptodev:5 [2022-04-08 22:41:44.437019] --log-level=user1:6 [2022-04-08 22:41:44.437072] --iova-mode=pa [2022-04-08 22:41:44.437098] --base-virtaddr=0x200000000000 [2022-04-08 22:41:44.437121] --match-allocations [2022-04-08 22:41:44.437145] --file-prefix=spdk_pid66198 [2022-04-08 22:41:44.437168] ]
  EAL: No available 1048576 kB hugepages reported
  EAL: No free 2048 kB hugepages reported on node 1
  TELEMETRY: No legacy callbacks, legacy socket not created
  [2022-04-08 22:41:44.519003] app.c: 543:spdk_app_start: *NOTICE*: Total cores available: 1
  [2022-04-08 22:41:44.648331] reactor.c: 943:reactor_run: *NOTICE*: Reactor started on core 0
  [2022-04-08 22:41:44.648394] accel_engine.c:1012:spdk_accel_engine_initialize: *NOTICE*: Accel engine initialized to use software engine.
  ```

리빌드 및 `spdk_tgt`이 정상적으로 수행되었으면 다른 터미널에서 문자 드라이버로 등록하는 과정을 수행합니다.

  ```
  [root@localhost spdk]# scripts/rpc.py bdev_nvme_attach_controller -b NVMe0 -t PCIe -a 0000:3b:00.0
  NVMe0n1
  [root@localhost spdk]# scripts/rpc.py bdev_nvme_cuse_register -n NVMe0
  ```

이때 `spdk_tgt`를 수행한 터미널에서 정상적으로 생성되었음을 암시하는 로그가 출력됩니다.

  ```
  [2022-04-08 22:45:37.183893] nvme_cuse.c: 972:nvme_cuse_start: *NOTICE*: Creating cuse device for controller
  [2022-04-08 22:45:37.184053] nvme_cuse.c: 763:cuse_session_create: *NOTICE*: fuse session for device spdk/nvme0 created
  [2022-04-08 22:45:37.184117] nvme_cuse.c: 763:cuse_session_create: *NOTICE*: fuse session for device spdk/nvme0n1 created
  ```

다른 터미널에서 문자 드라이버가 생성되었는지 확인해보겠습니다. 경로는 `/dev/spdk` 하위에 있습니다.

  ```
  [root@localhost spdk]# ls /dev/spdk/
  nvme0  nvme0n1
  ```

SPDK에 등록한 NVMe SSD의 문자 드라이버가 확인되면 `nvme` 명령을 사용해서 컨트롤러 정보를 확인해봅니다. `nvme` 명령에 `-H` 옵션을 추가하면 [그림 2]에서 보여준 NVMe controller register format을 보기 쉽게 변환해서 출력합니다.  (`-H` : `--human-readable`)

  ```
  [root@localhost spdk]# nvme id-ctrl /dev/spdk/nvme0 -H
  NVME Identify Controller:
  vid       : 0x8086
  ssvid     : 0x8086
  sn        : PHMB7435004J280CGN
  mn        : INTEL SSDPED1D280GA
  fr        : E2010325
  rab       : 0
  ieee      : 5cd2e4
  cmic      : 0
  [2:2] : 0     PCI
  [1:1] : 0     Single Controller
  [0:0] : 0     Single Port
  ...
  [root@localhost spdk]# scripts/rpc.py bdev_get_bdevs
  [
    {
    "name": "NVMe0n1",
      "aliases": [],
      "product_name": "NVMe disk",
      "block_size": 512,
      "num_blocks": 547002288,
      "uuid": "0b1f1ff5-4bb6-4fea-b436-0359ad12f7ee",
      "assigned_rate_limits": {
        "rw_ios_per_sec": 0,
        "rw_mbytes_per_sec": 0,
        "r_mbytes_per_sec": 0,
        "w_mbytes_per_sec": 0
      },
      "claimed": true,
      "zoned": false,
      "supported_io_types": {
        "read": true,
        "write": true,
        "unmap": true,
        "write_zeroes": true,
        "flush": true,
        "reset": true,
        "nvme_admin": true,
        "nvme_io": true
      },
      "driver_specific": {
        "nvme": {
          "pci_address": "0000:3b:00.0",
          "trid": {
            "trtype": "PCIe",
            "traddr": "0000:3b:00.0"
          },
          "cuse_device": "spdk/nvme0n1",
          "ctrlr_data": {
            "vendor_id": "0x8086",
            "model_number": "INTEL SSDPED1D280GA",
            "serial_number": "PHMB7435004J280CGN",
            "firmware_revision": "E2010325",
            "oacs": {
              "security": 1,
              "format": 1,
              "firmware": 1,
              "ns_manage": 0
            }
          },
          "vs": {
            "nvme_version": "1.0"
          },
          "ns_data": {
            "id": 1
          },
          "security": {
            "opal": false
          }
        }
      }
    }
  ]
  ```

`nvme id-ctrl`로 확인한 NVMe SSD 정보와 `bdev_get_bdevs`가 동일한 것을 확인할 수 있습니다. 반대로 NVMe 컨트롤러 해제와 마찬가지로 문자 드라이버 등록을 해제하려면 `bdev_nvme_cuse_unregister` 기능을 사용하면 됩니다.

  ```
  [root@localhost spdk]# scripts/rpc.py bdev_nvme_cuse_unregister -n NVMe0
  [root@localhost spdk]# ls /dev/spdk/nvme0
  ls: cannot access /dev/spdk/nvme0: No such file or directory
  ```

이처럼 SPDK에서 제공하는 문자 드라이버 기능을 통해 어플리케이션에서도 NVMe SSD를 제어할 수 있습니다. 

  * 참고
    - https://spdk.io/doc/bdev.html
    - https://spdk.io/doc/nvme.html

### lvol 생성

TODO: 논리 볼륨에 대한 기본 설명과 blobstore 아키텍처를 따른다는 간단한 설명..추가..?
다음으로 논리 볼륨을 생성해보겠습니다. SPDK에서는 논리 볼륨 기능을 lvol 모듈에서 제공합니다. lvol은 리눅스 커널에서 제공하는 LVM(Logical Volume Manager)의 LV(Logical Volume)과 유사한 기능입니다. lvol을 생성하기 위해서 SPDK에 등록한 NVMe SSD를 논리 볼륨 저장소에 등록하는 작업이 선행되어야 합니다. 이는 LVM에서 물리 장치인 PV(Phisical Volume)를 VG(Volume Group)에 등록하는 작업과 유사합니다. SPDK에서 논리 볼륨 저장소는 lvstore로 불립니다. lvstore는 `bdev_lvol_create_lvstore` 기능으로 수행할 수 있습니다. `bdev_lvol_create_lvstore`의 첫번째 인자는 `bdev_get_bdevs` 기능으로 출력된 장치의 이름이 입력되며, 두번째 인자는 등록할 신규 논리 볼륨 저장소의 이름입니다.

  ```
  [root@localhost spdk]# scripts/rpc.py bdev_lvol_create_lvstore NVMe0n1 lvs
  1818d45a-3a05-42c9-bbb2-9229cc25ac49
  ```

NVMe SSD가 논리 볼륨 저장소에 정상적으로 등록되면 생성된 lvstore의 uuid를 출력합니다. 현재 SPDK에서 생성된 논리 볼륨 저장소는 `bdev_lvol_get_lvstores` 기능으로 확인할 수 있으며, 등록된 장치 정보를 출력하는 `bdev_get_bdevs` 기능으로는 확인할 수 없습니다.

  ```
  [root@localhost spdk]# scripts/rpc.py bdev_lvol_get_lvstores
  [
    {
      "uuid": "1818d45a-3a05-42c9-bbb2-9229cc25ac49",
        "name": "lvs",
        "base_bdev": "NVMe0n1",
        "total_data_clusters": 66706,
        "free_clusters": 66706,
        "block_size": 512,
        "cluster_size": 4194304
    }
  ]
  ```

논리 볼륨 저장소 삭제는 `bdev_lvol_delete_lvstore` 기능을 사용합니다.

  ```
  [root@localhost spdk]# scripts/rpc.py bdev_lvol_delete_lvstore -l lvs
  [root@localhost spdk]# scripts/rpc.py bdev_lvol_get_lvstores
  []
  ```

다음으로 논리 볼륨 저장소를 생성했으면 논리 볼륨을 생성해보겠습니다. 논리 볼륨 생성은 `bdev_lvol_create` 기능을 사용합니다. `bdev_lvol_create`의 첫번째 인자는 생성할 논리 볼륨의 이름이며, 두번째 이자는 논리 볼륨의 크기이며 기본 단위는 MiB 입니다. 마지막으로 `-l` 옵션으로 논리 볼륨 저장소의 이름 또는 uuid를 입력합니다. 예제로 1GB 용량의 논리 볼륨을 생성해보겠습니다.

  ```
  [root@localhost spdk]# scripts/rpc.py bdev_lvol_create lvol1 1024 -l lvs
  68ba7bbc-d26b-464b-ae12-f48a62512b0d
  ```

논리 볼륨이 정상적으로 생성되면 마찬가지로 lvol의 uuid를 출력합니다. SPDK에서 생성된 논리 볼륨은 장치로 분류되기 때문에 `bdev_get_bdevs` 기능으로 확인할 수 있으며, `bdev_get_lvstores`와 같이 논리 볼륨 리스트만 출력 가능한 명령은 제공하지 않습니다.

  ```
  [root@localhost spdk]# scripts/rpc.py bdev_get_bdevs
  [
    {...},
    {
        "name": "68ba7bbc-d26b-464b-ae12-f48a62512b0d",
        "aliases": [
            "lvs/lvol1"
        ],
        "product_name": "Logical Volume",
        "block_size": 512,
        "num_blocks": 2097152,
        "uuid": "68ba7bbc-d26b-464b-ae12-f48a62512b0d",
        "assigned_rate_limits": {
            "rw_ios_per_sec": 0,
            "rw_mbytes_per_sec": 0,
            "r_mbytes_per_sec": 0,
            "w_mbytes_per_sec": 0
        },
        "claimed": false,
        "zoned": false,
        "supported_io_types": {
            "read": true,
            "write": true,
            "unmap": true,
            "write_zeroes": true,
            "flush": false,
            "reset": true,
            "nvme_admin": false,
            "nvme_io": false
        },
        "driver_specific": {
            "lvol": {
                "lvol_store_uuid": "6579330a-4748-472c-a249-adce070ec15e",
                "base_bdev": "NVMe0n1",
                "thin_provision": false,
                "snapshot": false,
                "clone": false
            }
        }
    }
  ]
  ```

`bdev_get_bdevs` 수행 결과, 논리 볼륨 저장소 lvs에서 1GB 용량을 갖는 논리 볼륨 lovl1이 생성된 것을 확인할 수 있습니다. 이때 볼륨의 용량은 `block_size`와 `num_blocks` 값으로 계산할 수 있습니다. 위 예시에서는 512 byte 크기를 갖는 블록이 2,097,152개 생성되어 전체 1,073,741,824 byte(=1GB) 용량이 할당되었음을 확인할 수 있습니다.

생성된 논리 볼륨 삭제는 `bdev_lvol_delete` 기능을 통해 수행할 수 있습니다.

  ```
  [root@localhost spdk]# scripts/rpc.py bdev_lvol_delete lvs/lvol1
  ```

이외에도 논리 볼륨은 스냅샷, 클론, 크기 변경 등, 다양한 기능들 제공합니다. 추가 기능에 대한 설명은 [logical volumes document](https://spdk.io/doc/logical_volumes.html)에서 확인할 수 있습니다.

  * 참고
    - https://spdk.io/doc/bdev.html
    - https://spdk.io/doc/logical_volumes.html

### RAID 생성

SPDK는 소프트웨어 기반의 RAID 볼륨을 지원합니다. 다만 현재까지 공식적으로 제공하는 기능은 RAID-0 뿐입니다. RAID-0은 RAID 볼륨에 참여된 장치들에 분산되는 구조로 성능은 뛰어나지만 하나의 장치에 이상이 생길 경우 데이터의 무결성이 깨질 수 있습니다. 대부분의 소프트웨어 RAID는 RAID 구성 정보를 참여한 장치에 직접 기록해서 관리하지만, SPDK에서 제공하는 RAID-0은 장치에 정보를 기록하지 않아, SPDK 프레임워크를 재시작 할 경우 구성했던 RAID 정보를 불러올 수 없습니다. (※RAID와 반대로 논리 볼륨은 재시작을 하더라도 구성 정보를 불러옵니다.)

RAID-0 생성은 `bdev_raid_create` 기능을 통해 수행할 수 있습니다. 이때 생성할 RAID 이름(`-n`)과 스트라이프 크기(`-z`), RAID 번호(`-r`), 등록할 장치(`-b`)를 입력해야 합니다.

  ```
  [root@localhost spdk]# scripts/rpc.py bdev_raid_create -n raid0 -z 64 -r 0 -b "lvol1 lvol2 lvol3 lvol4"
  ```

아무런 결과가 출력되지 않았다면 정상적으로 생성되었다는 뜻입니다. RAID 장치 정보는 `bdev_raid_get_bdevs` 기능을 통해 확인할 수 있는데, 이때 인자값으로 RAID의 상태 카테고리를 입력해야 합니다. 카테고리는 `all`, `online`, `configuring`, `offline`이 있습니다.

  ```
  [root@localhost spdk]# scripts/rpc.py bdev_raid_get_bdevs all
  raid0
  ```

아쉽게도 RAID에 대한 정보를 확인하는 명령은 제공되지 않습니다. 현재 구현된 RAID 관련된 기능은 생성, 리스트 출력, 삭제 기능뿐입니다. `bdev_get_bdevs` 결과에서도 구성한 RAID 정보는 확인할 수 없습니다. 삭제는 `bdev_raid_delete` 기능을 통해 수행합니다.

  ```
  [root@localhost spdk]# scripts/rpc.py bdev_raid_delete raid0
  ```

RAID 생성과 마찬가지로 정상적으로 삭제된 경우 아무 결과를 출력하지 않습니다. SPDK의 경우 아직까지 다양한 기능을 지원하지 않으며, 현재까지 구현된 기능만으로 사용할 수 있는 환경으로는 안정성은 낮지만 높은 성능이 제공되어야 하는 캐시 역할로 적합해 보입니다.

하지만 SPDK에서 RAID 기능 구현 계획이 없는것은 아닌것 같습니다. 커뮤니티에는 RAID-5 구현에 대한 필요성이 언급되었으며([링크](https://lists.01.org/hyperkitty/list/spdk@lists.01.org/thread/DBSZDNBGNWV6PD7MOF7V5M7EOQP4EVTJ/)), RAID-1의 경우 일부 코드가 [yupeng0921 github](https://github.com/yupeng0921/spdk/tree/raid1/module/bdev/raid1)에 공개되어 있습니다.

또한 현재 SPDK github에는 RAID-5와 관련된 [코드](https://github.com/spdk/spdk/blob/master/module/bdev/raid/raid5.c)를 일부 확인할 수 있습니다.  그렇다면 가까운 미래에 RAID-5를 사용할 수 있을 것으로 생각하고 현재 SPDK에서 RAID-5 볼륨을 생성하는 방법을 실습해보겠습니다.

먼저 `./configure`에서 `--with-raid5` 옵션을 추가하고 리빌드를 수행해야 합니다. 

  ```
  [root@localhost spdk]# ./configure --with-raid5
  [root@localhost spdk]# make -j 40
  [root@localhost spdk]# ./build/bin/spdk_tgt
  ```

리빌드 및 `spdk_tgt` 시작을 완료하고 `bdev_raid_create` 기능에서 RAID 레벨(`-r`)을 5로 입력하면 현재 코드에서 구현된 RAID-5 볼륨을 생성할 수 있습니다. 하지만 RAID-0과 마찬가지로 재시작 시 구성했던 볼륨 정보는 사라집니다.

  ```
  [root@localhost spdk]# scripts/rpc.py bdev_raid_create -n raid5 -z 64 -r 5 -b "lvol1 lvol2 lvol3 lvol4"
  [root@localhost spdk]# scripts/rpc.py bdev_raid_get_bdevs all
  raid5
  ```

&nbsp;

## SPDK 성능 측정

### 테스트 환경

### bdevperf 테스트

  * spdk에서는 자체적으로 `bdevperf`와 `fio` 성능 테스트 툴을 제공한다. (당연한것이 호환되는게 없음..)

### bdevperf

  * `bdevperf`는 `<path to spdk repo>/test/bdev/bdevperf` 디렉토리에 존재하며 간단하게 `test_config.sh`를 수행하여 테스트를 수행해볼 수 있다.
  ```
  [root@localhost spdk]# cd test/bdev/bdevperf`
  [root@localhost bdevperf]# ls -l
  -rwxr-xr-x 1 root root 7740256 Jan 13 05:22 bdevperf
  -rw-r--r-- 1 root root   56826 Nov  1 06:27 bdevperf.c
  -rw-r--r-- 1 root root    1840 Jan 13 05:22 bdevperf.d
  -rw-r--r-- 1 root root  227480 Jan 13 05:22 bdevperf.o
  -rwxr-xr-x 1 root root    2910 Nov  1 06:27 bdevperf.py
  -rw-r--r-- 1 root root     587 Nov  1 06:27 common.sh
  -rw-r--r-- 1 root root     473 Nov  1 06:27 conf.json
  -rw-r--r-- 1 root root    2017 Nov  1 06:27 Makefile
  -rwxr-xr-x 1 root root    1257 Nov  1 06:27 test_config.sh
  [root@localhost bdevperf]# ./test_config.sh
  ...
  =============================================================
  Total                       : 2228736.00 IOPS    2176.50 MiB/s'
  22:44:02      -- bdevperf/common.sh@28 -- # grep -oE '[0-9]+'
  22:44:02       -- ./test_config.sh@39 -- # [[ 4 == \4 ]]
  22:44:02       -- ./test_config.sh@40 -- # cleanup
  22:44:02       -- bdevperf/common.sh@32 -- # rm -f /root/spdk/test/bdev/bdevperf/test.conf
  22:44:02       -- ./test_config.sh@41 -- # trap - SIGINT SIGTERM EXIT
  ```
  * 아 이렇게 동작하구나~ 그러면 원하는데로 돌려보자, 옵션은 `./bdevperf --help`로 찾아볼 수 있다.
  * 그 전에, 일반적으로 벤치마킹 툴을 사용해봤으면 알겠지만, 성능을 측정할 대상(경로 또는 장치)을 지정해야하는데 spdk는 경로가 존재하지 않기 때문에 테스트할 대상을 지정할 설정 파일이 필요하다.
  * 샘플로 `conf.json`을 보면 json 타입으로 어떤 장치인지 지정되어 있는것을 확인할 수 있다.
  ```
  [root@localhost bdevperf]# cat conf.json
  {
    "subsystems": [
    {
      "subsystem": "bdev",
      "config": [
      {
        "method": "bdev_malloc_create",
        "params": {
          "name": "Malloc0",
          "num_blocks": 102400,
          "block_size": 512
        }
      },
      {
        "method": "bdev_malloc_create",
        "params": {
          "name": "Malloc1",
          "num_blocks": 102400,
          "block_size": 512
        }
      }
      ]
    }
    ]
  }
```
    - 위 내용을 확인해보면 각각 50MiB(512 * 102400) 용량을 갖는 Malloc1과 Malloc2를 메모리에 생성하겠다는 것이다.  * 그렇다면 128 iodepth를 가지며, 4KiB 블록 크기로 읽기 테스트를 300초 동안 수행해보자
    ```
    [root@localhost bdevperf]# ./bdevperf -t 300 -c ./conf.json -q 128 -o 4096 -w read
    [2022-01-13 22:47:33.489389] Starting SPDK v22.01-pre git sha1 ed8be4ad0 / DPDK 21.08.0 initialization...
    [2022-01-13 22:47:33.489561] [ DPDK EAL parameters: [2022-01-13 22:47:33.489591] bdevperf [2022-01-13 22:47:33.489612] --no-shconf [2022-01-13 22:47:33.489635] -c 0x1 [2022-01-13 22:47:33.489656] --log-level=lib.eal:6 [2022-01-13 22:47:33.489676] --log-level=lib.cryptodev:5 [2022-01-13 22:47:33.489697] --log-level=user1:6 [2022-01-13 22:47:33.489718] --iova-mode=pa [2022-01-13 22:47:33.489739] --base-virtaddr=0x200000000000 [2022-01-13 22:47:33.489761] --match-allocations [2022-01-13 22:47:33.489781] --file-prefix=spdk_pid174830 [2022-01-13 22:47:33.489804] ]
    EAL: No available 1048576 kB hugepages reported
    EAL: No free 2048 kB hugepages reported on node 1
    TELEMETRY: No legacy callbacks, legacy socket not created
    [2022-01-13 22:47:33.593973] app.c: 543:spdk_app_start: *NOTICE*: Total cores available: 1
    [2022-01-13 22:47:33.880832] reactor.c: 943:reactor_run: *NOTICE*: Reactor started on core 0
    [2022-01-13 22:47:33.881331] accel_engine.c:1012:spdk_accel_engine_initialize: *NOTICE*: Accel engine initialized to use software engine.
    Running I/O for 300 seconds...
    Job: Malloc0 (Core Mask 0x1)
    Malloc0             :  407177.81 IOPS    1590.54 MiB/s
    Job: Malloc1 (Core Mask 0x1)
    Malloc1             :  407177.81 IOPS    1590.54 MiB/s
    =============================================================
    Total                       :  814355.63 IOPS    3181.08 MiB/s
    ```
    - 결과처럼 Malloc0과 Malloc1에 테스트를 수행한 것을 알 수 있다.
  * 다음으로 메모리로 생성한 장치가 아닌 실제 NVMe SSD의 spdk 드라이버 성능을 측정해보자
  * 마찬가지로 conf 파일을 설정해야하는데, 이는 `scripts/get_nvme.sh` 스크립트를 이용하여 NVMe 설정 파일을 생성할 수 있다.
  ```
  [root@localhost bdevperf]# /root/spdk/scripts/gen_nvme.sh --json-with-subsystems | jq . > nvme.json
  [root@localhost bdevperf]# cat nvme.json
  {
    "subsystems": [
    {
      "subsystem": "bdev",
      "config": [
      {
        "method": "bdev_nvme_attach_controller",
        "params": {
          "trtype": "PCIe",
          "name": "Nvme0",
          "traddr": "0000:3b:00.0"
        }
      }
      ]
    }
    ]
  }
  ```
  * NVMe 장치에 bdevperf를 수행해보자, 옵션은 MallocX와 동일하지만 설정 파일이 변경되었으니 -c 옵션에 설정 경로만 다르게 해준다.
  ```
  [root@localhost bdevperf]# ./bdevperf -t 300 -c ./nvme.json -q 128 -o 4096 -w read
  [2022-01-13 23:15:52.588048] Starting SPDK v22.01-pre git sha1 ed8be4ad0 / DPDK 21.08.0 initialization...
  [2022-01-13 23:15:52.588245] [ DPDK EAL parameters: [2022-01-13 23:15:52.588276] bdevperf [2022-01-13 23:15:52.588297] --no-shconf [2022-01-13 23:15:52.588319] -c 0x1 [2022-01-13 23:15:52.588354] --log-level=lib.eal:6 [2022-01-13 23:15:52.588375] --log-level=lib.cryptodev:5 [2022-01-13 23:15:52.588396] --log-level=user1:6 [2022-01-13 23:15:52.588417] --iova-mode=pa [2022-01-13 23:15:52.588439] --base-virtaddr=0x200000000000 [2022-01-13 23:15:52.588460] --match-allocations [2022-01-13 23:15:52.588481] --file-prefix=spdk_pid241533 [2022-01-13 23:15:52.588503] ]
  EAL: No available 1048576 kB hugepages reported
  EAL: No free 2048 kB hugepages reported on node 1
  TELEMETRY: No legacy callbacks, legacy socket not created
  [2022-01-13 23:15:52.683909] app.c: 543:spdk_app_start: *NOTICE*: Total cores available: 1
  [2022-01-13 23:15:52.951868] reactor.c: 943:reactor_run: *NOTICE*: Reactor started on core 0
  [2022-01-13 23:15:52.952347] accel_engine.c:1012:spdk_accel_engine_initialize: *NOTICE*: Accel engine initialized to use software engine.
  Running I/O for 300 seconds...
  Job: Nvme0n1 (Core Mask 0x1)
  Nvme0n1             :  334248.13 IOPS    1305.66 MiB/s
  =============================================================
  Total                       :  334248.13 IOPS    1305.66 MiB/s
  ```

### FIO 테스트

  * 'fio에 대한 간단한 설명 추가'
  * fio 테스트를 위해서는 fio 소스 코드를 빌드해야 한다. 관련 내용은 [여기](https://github.com/spdk/spdk/tree/master/examples/nvme/fio_plugin)를 참고해서 설치하면 된다.
  ```
  [root@localhost ~]# git clone https://github.com/axboe/fio
  [root@localhost ~]# cd fio
  [root@localhost fio]# make
  [error]
  ```
    - gcc 버전이 낮다.. [여기](https://m.blog.naver.com/alice_k106/221019680668)를 참고해서 올리자..
  * 다시 시작.. 성공!
  ```
  LINK t/read-to-pipe-async
  LINK t/fio-btrace2fio
  LINK t/io_uring
  [root@localhost fio]# ls -l fio
  -rwxr-xr-x 1 root root 6400472 Jan 13 23:45 fio
  [root@localhost fio]# cd ~/spdk
  [root@localhost spdk]# ./configure --with-fio=/root/fio
  Notice: ISA-L, compression & crypto require NASM version 2.14 or newer. Turning off default ISA-L and crypto features.
  Using default SPDK env in /root/spdk/lib/env_dpdk
  Using default DPDK in /root/spdk/dpdk/build
  Creating mk/config.mk...done.
  Creating mk/cc.flags.mk...done.
  [root@localhost spdk]# make 
  ...
  CXX test/cpp_headers/string.o
  CXX test/cpp_headers/gpt_spec.o
  CXX test/cpp_headers/nvme_ocssd.o
  LINK dif_ut
  LINK ftl_wptr_ut
  LINK ftl_io_ut
  [root@localhost spdk]# ls build/fio
  total 12852
  -rwxr-xr-x 1 root root 8665272 Jan 13 23:49 spdk_bdev
  -rwxr-xr-x 1 root root 4490272 Jan 13 23:49 spdk_nvme
  ```
  * fio 를 실행할 때에는 spdk의 플러그인을 사용하려면 `LD_PRELOAD` 매개변수를 통해 spdk의 경로를 입력해야한다.
  * 그렇다면 한번 실행해보자, 먼저 bdevperf와 동일하게 NVMe 장치 설정을 가져온다.
  ```
  [root@localhost spdk]# cd examples/bdev/fio_plugin
  [root@localhost fio_plugin]# /root/spdk/scripts/gen_nvme.sh --json-with-subsystems | jq . > nvme.json
  [root@localhost fio_plugin]# cat nvme.json
  {
    "subsystems": [
    {
      "subsystem": "bdev",
        "config": [
        {
          "method": "bdev_nvme_attach_controller",
          "params": {
            "trtype": "PCIe",
            "name": "Nvme0",
            "traddr": "0000:3b:00.0"
          }
        }
        ]
    }
    ]
  }
  ```
  * 이 떄, fio config에 `nvme.json`을 설정하면 성능 측정 전에 자동으로 SPDK에 NVMe 컨트롤러를 연결한다. 따라서 기존에 SPDK에 attach한 NVMe 컨트롤러가 있다면 해제해야한다.
  ```
  [root@localhost fio_plugin]# scripts/rpc.py bdev_nvme_detach_controller NVMe0
  [root@localhost fio_plugin]# scripts/rpc.py bdev_nvme_get_controllers
  []
  ```
  * fio 테스트 옵션은 [spdk performance report](https://ci.spdk.io/download/performance-reports/SPDK_nvme_bdev_perf_report_2110.pdf)의 'Test Case 1'의 설정을 참고했다.
  ```
  [root@localhost fio_plugin]# cat run_fio.fio
  [global]
  ioengine=/root/spdk/build/fio/spdk_bdev
  spdk_json_conf=/root/spdk/examples/bdev/fio_plugin/nvme.json

  gtod_reduce=1
  direct=1
  thread=1
  norandommap=1
  time_based=1
  ramp_time=60s
  runtime=300s
  rw=read
  bs=4k
  numjobs=1

  [filename0]
  filename=Nvme0n1
  iodepth=128

  [root@localhost fio_plugin]# /root/fio/fio ./run_fio.fio
  filename0: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=spdk_bdev, iodepth=128
  fio-3.29-7-g01686
  Starting 1 thread
  [2022-01-20 22:49:33.573673] Starting SPDK v22.01-pre git sha1 ed8be4ad0 / DPDK 21.08.0 initialization...
  [2022-01-20 22:49:33.573890] [ DPDK EAL parameters: [2022-01-20 22:49:33.573922] fio [2022-01-20 22:49:33.573944] --no-shconf [2022-01-20 22:49:33.573965] -c 0x1 [2022-01-20 22:49:33.573986] --log-level=lib.eal:6 [2022-01-20 22:49:33.574007] --log-level=lib.cryptodev:5 [2022-01-20 22:49:33.574027] --log-level=user1:6 [2022-01-20 22:49:33.574062] --iova-mode=pa [2022-01-20 22:49:33.574082] --base-virtaddr=0x200000000000 [2022-01-20 22:49:33.574103] --match-allocations [2022-01-20 22:49:33.574124] --file-prefix=spdk_pid269971 [2022-01-20 22:49:33.574145] ]
  EAL: No available 1048576 kB hugepages reported
  EAL: No free 2048 kB hugepages reported on node 1
  TELEMETRY: No legacy callbacks, legacy socket not created
  [2022-01-20 22:49:33.707015] accel_engine.c:1012:spdk_accel_engine_initialize: *NOTICE*: Accel engine initialized to use software engine.
  Jobs: 1 (f=1): [R(1)][100.0%][r=2602MiB/s][r=666k IOPS][eta 00m:00s]
  filename0: (groupid=0, jobs=1): err= 0: pid=270034: Thu Jan 20 22:55:33 2022
    read: IOPS=666k, BW=2603MiB/s (2730MB/s)(763GiB/300001msec)
      bw (  MiB/s): min= 2567, max= 2614, per=100.00%, avg=2604.31, stdev= 7.14, samples=600
      iops        : min=657376, max=669316, avg=666702.32, stdev=1828.62, samples=600
    cpu          : usr=100.00%, sys=0.00%, ctx=724, majf=0, minf=139
    IO depths    : 1=0.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=100.0%
      submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
      complete  : 0=0.0%, 4=100.0%, 8=0.1%, 16=0.1%, 32=0.1%, 64=0.1%, >=64=0.1%
      issued rwts: total=199938792,0,0,0 short=0,0,0,0 dropped=0,0,0,0
      latency   : target=0, window=0, percentile=100.00%, depth=128

  Run status group 0 (all jobs):
    READ: bw=2603MiB/s (2730MB/s), 2603MiB/s-2603MiB/s (2730MB/s-2730MB/s), io=763GiB (819GB), run=300001-300001msec
  ```
  * 참고
    - https://www.intel.com/content/www/us/en/developer/articles/technical/evaluate-performance-for-storage-performance-development-kit-spdk-based-nvme-ssd.html
    - https://github.com/spdk/spdk/issues/1104

### 실시간 모니터링 방법

&nbsp;

마치며
-----

끝내는 말(You Died)

&nbsp;

각주
---

[^1]: vfio
[^2]: uio
[^3]: rpc
[^4]: cuse
