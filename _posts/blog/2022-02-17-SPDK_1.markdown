---
layout:     post
title:      "자 따라해봐요 이렇게~ 그래, 한번 해보자 SPDK 실습"
date:       2022-02-17
author:     김 태훈 (thkim@gluesys.com)
categories: blog
tags:       [SPDK, NVMe, SSD, Flash, Memory, RDMA, Storage]
cover:      "/assets/SPDK_maincover.jpg"
main:       "/assets/SPDK_maincover.jpg"
---

안녕하세요. 오늘은 SPDK의 최신 코드를 이용해서 테스트 환경을 구축해보고 SPDK의 일부 기능을 실습하도록 하겠습니다.

&nbsp;

## SPDK 간단한 설명

지난 [포스팅](https://tech.gluesys.com/blog/2022/02/18/SPDK_1.html)에서 소개한 바와 같이 SPDK는 기존에 정통적인 커널 계층의 블록 드라이버 레이어를 걷어내고 사용자 공간(userspace) 계층에서 드라이버를 구현하여 NVMe와 같은 초고속 SSD 장치를 효율적으로 사용하기 위한 프레임워크입니다. SPDK 코드에는 NVMe 장치에 기본적인 기능(open, read, write, close 등)을 수행하는 드라이버와 개념의 코드들과, 드라이버를 이용하여 기존 커널에서 제공하던 블록 장치 기술(인터페이스, 논리 볼륨, 큐 배치, 스케줄러 등)의 코드들로 구성됩니다. SPDK에서는 이러한 기능들을 'bdev' 이라고 표현합니다.

[블록 계층 관련 그림 추가, 출처 표기]
SPDK의 bdev는 기존 커널의 장치 드라이버보다 상위 계층에서 동작하는 블록 계층과 동일한 역할을 수행하는 C 라이브러리 입니다. 블록 계층은 저장 장치를 이용하여 스토리지의 기본 기능들을 제공하는 영역인데, 대표적으로 논리 볼륨과 소프트웨어 RAID, 압축/중복 제거 등이 있습니다. SPDK는 기존 커널에서 제공하는 스토리지 기능들을 일부 제공하고 있으며, 이러한 플러그인 형태의 구현된 기능들을 bdev module로 표현합니다. 현재 bdev module에서 제공하는 기능은 다음과 같습니다.
  * Ceph RBD(RADOS Block Device)
  * Thin Provisioning
  * Device Crypto
  * Throughput Delay
  * GPT(for GUID partition table) & Partitioning
  * iSCSI Initiator (binding LUN to bdev)
  * Open CAS Framework(OCF)
  * Malloc(ramdisk)
  * Null(Similar to '/dev/null')
  * NVMe Device
  * Logical Volume
  * Passthrough
  * Pmem
  * S/W RAID
  * Split
  * Uring
  * Virtio-Block & Virtio-SCSI using vhost
익숙한 기능들도, 처음 보는 단어들이 보이네요. 모듈들의 자세한 설명은 [링크](https://spdk.io/doc/bdev.html)에서 확인하실 수 있습니다. 이외에도 개발자는 SPDK에서 제공하는 bdev 라이브러리([bdev.h](https://spdk.io/doc/bdev_8h.html))를 이용하여 스토리지 기능을 유저 레벨에서 구현할 수 있습니다. 물론 이를 위해서는 관련 기술을 잘 알고 있어야 합니다. 오늘은 우리에게~~제가~~ 익숙한 몇몇 모듈들을 사용해 보도록 하겠습니다

  &nbsp;

## SPDK 설치

먼저 SPDK 깃허브에서 master 브랜치의 최신 코드를 테스트 장비로 가져옵니다.

  ```
  [root@localhost ~]# git clone https://github.com/spdk/spdk
  [root@localhost ~]# cd spdk
  ```

그리고 설치할 코드의 의존성 패키지를 설치합니다.

  ```
  [root@localhost spdk]# scripts/pkgdep.sh --all
  ```

패키지 설치가 완료되면 빌드를 해줍니다. 이때 `./configure` 스크립트를 실행하는데, 어떤 기능들을 활성할지 옵션으로 입력해야 합니다. 먼저 기본값으로 진행합니다.

  ```
  [root@localhost spdk]# ./configure
  [root@localhost spdk]# make -j 8
  ```

빌드가 완료되면 SPDK 드라이버를 사용할 수 있도록 커널에서 소유하고있는 NVMe 장치를 연결 해제해야 합니다. 커널은 운영체제가 부팅되면서 하드웨어 장치들을 인식하고 관련된 드라이버를 실행하여 장치를 사용할 수 있도록 준비합니다. 이때 로드된 드라이버에서 장치에 대한 오너쉽을 해제해야 SPDK에서 장치의 오너쉽을 가져올 수 있습니다.
현재 테스트 장비에는 인텔의 280GB NVMe SSD가 설치되어 있습니다. 해당 장치를 SPDK에서 사용할 수 있도록 준비해보겠습니다.

  ```
  [root@localhost spdk]# nvme list
  Node             SN                   Model                                    Namespace Usage                      Format           FW Rev
  ---------------- -------------------- ---------------------------------------- --------- -------------------------- ---------------- --------
  /dev/nvme0n1     PHMB7435004J280CGN   INTEL SSDPED1D280GA                      1         280.07  GB / 280.07  GB    512   B +  0 B   E2010325
  [root@localhost spdk]# lsblk | grep nvme
  nvme0n1 259:0    0 260.9G  0 disk
  [root@localhost spdk]# scripts/setup.sh
  0000:80:04.2 (8086 2021): Already using the uio_pci_generic driver
  0000:80:04.3 (8086 2021): Already using the uio_pci_generic driver
  0000:80:04.0 (8086 2021): Already using the uio_pci_generic driver
  0000:80:04.1 (8086 2021): Already using the uio_pci_generic driver
  0000:80:04.6 (8086 2021): Already using the uio_pci_generic driver
  0000:80:04.7 (8086 2021): Already using the uio_pci_generic driver
  0000:80:04.4 (8086 2021): Already using the uio_pci_generic driver
  0000:80:04.5 (8086 2021): Already using the uio_pci_generic driver
  0000:00:04.2 (8086 2021): Already using the uio_pci_generic driver
  0000:00:04.3 (8086 2021): Already using the uio_pci_generic driver
  0000:00:04.0 (8086 2021): Already using the uio_pci_generic driver
  0000:00:04.1 (8086 2021): Already using the uio_pci_generic driver
  0000:00:04.6 (8086 2021): Already using the uio_pci_generic driver
  0000:00:04.7 (8086 2021): Already using the uio_pci_generic driver
  0000:00:04.4 (8086 2021): Already using the uio_pci_generic driver
  0000:00:04.5 (8086 2021): Already using the uio_pci_generic driver
  0000:3b:00.0 (8086 2700): nvme -> uio_pci_generic
  ```

드라이버 해제가 완료되었습니다. 다시 조회해볼까요?

  ```
  [root@localhost spdk]# nvme list
  [root@localhost spdk]# lsblk | grep nvme
  ```

결과가 나오지 않습니다. 커널의 관련 드라이버에서 장치의 오너쉽을 해제했기 때문입니다. 관련 기술로 vfio[^1] 또는 uio[^2] 기술을 이용하는데, 자세한 설명은 본 포스팅의 목적과 다르니 이 부분은 향후 심화 과정으로 다뤄보겠습니다. 간단한 내용은 [링크](https://spdk.io/doc/concepts.html)를 참고하시면 되겠습니다. SPDK 테스트가 끝나고 다시 커널에 오너쉽을 넘기려면 `reset` 옵션을 추가하면 됩니다.

  ```
  [root@localhost spdk]# scripts/setup.sh reset
  0000:3b:00.0 (8086 2700): uio_pci_generic -> nvme
  0000:80:04.2 (8086 2021): uio_pci_generic -> no driver
  0000:80:04.3 (8086 2021): uio_pci_generic -> no driver
  0000:80:04.0 (8086 2021): uio_pci_generic -> no driver
  0000:80:04.1 (8086 2021): uio_pci_generic -> no driver
  0000:80:04.6 (8086 2021): uio_pci_generic -> no driver
  0000:80:04.7 (8086 2021): uio_pci_generic -> no driver
  0000:80:04.4 (8086 2021): uio_pci_generic -> no driver
  0000:80:04.5 (8086 2021): uio_pci_generic -> no driver
  0000:00:04.2 (8086 2021): uio_pci_generic -> no driver
  0000:00:04.3 (8086 2021): uio_pci_generic -> no driver
  0000:00:04.0 (8086 2021): uio_pci_generic -> no driver
  0000:00:04.1 (8086 2021): uio_pci_generic -> no driver
  0000:00:04.6 (8086 2021): uio_pci_generic -> no driver
  0000:00:04.7 (8086 2021): uio_pci_generic -> no driver
  0000:00:04.4 (8086 2021): uio_pci_generic -> no driver
  0000:00:04.5 (8086 2021): uio_pci_generic -> no driver
  [root@localhost spdk]# lsblk | grep nvme
  nvme0n1 259:0    0 260.9G  0 disk
  ```

소유권이 커널로 넘어갔네요. 간단한 예제를 수행해 보겠습니다.`build/exmpales/hello_world`를 수행합니다.

  ```
  [root@localhost spdk]# build/examples/hello_world
  [2022-01-13 03:44:04.916653] Starting SPDK v22.01-pre git sha1 ed8be4ad0 / DPDK 21.08.0 initialization...
  [2022-01-13 03:44:04.916839] [ DPDK EAL parameters: [2022-01-13 03:44:04.916872] hello_world [2022-01-13 03:44:04.916896] -c 0x1 [2022-01-13 03:44:04.916919] --log-level=lib.eal:6 [2022-01-13 03:44:04.916942] --log-level=lib.cryptodev:5 [2022-01-13 03:44:04.916986] --log-level=user1:6 [2022-01-13 03:44:04.917014] --iova-mode=pa [2022-01-13 03:44:04.917040] --base-virtaddr=0x200000000000 [2022-01-13 03:44:04.917062] --match-allocations [2022-01-13 03:44:04.917086] --file-prefix=spdk0 [2022-01-13 03:44:04.917111] --proc-type=auto [2022-01-13 03:44:04.917133] ]
  EAL: No available 1048576 kB hugepages reported
  EAL: No free 2048 kB hugepages reported on node 1
  TELEMETRY: No legacy callbacks, legacy socket not created
  Initializing NVMe Controllers
  Attaching to 0000:3b:00.0
  Attached to 0000:3b:00.0
  Using controller INTEL SSDPED1D280GA  (PHMB7435004J280CGN  ) with 1 namespaces.
    Namespace ID: 1 size: 280GB
    Initialization complete.
    INFO: using host memory buffer for IO
    Hello world!
  ```

아 좋습니다. 커널의 드라이버와 연결 해제한 NVMe 장치를 SPDK에서 직접 통신하여 SSD의 컨트롤러 정보를 불러왔군요. 이렇게 커널의 드라이버 없이 SPDK를 통해 장치와 통신하는 예제를 실행해봤습니다. 예제의 코드는 `examples/nvme/hello_world/hello_world.c`에서 확인할 수 있습니다.

  * 참고
    - https://spdk.io/doc/getting_started.html

&nbsp;

## SPDK 실습

SPDK 에서 기본적으로 제공하는 기능들은 모두 rpc[^3]로 통신하며, 요청과 응답은 JSON 포맷을 사용합니다. 따라서 rpc 통신을 위해서는 소켓을 오픈해야 합니다. 이는 기존 커널에서 시스템 콜을 통해 장치 드라이버에 사용자 명령을 전달하는 것과 같은 구조입니다. 옆 동료가 쿠쿠다스를 부수고 있군요. 더 깊게 들어가지 말고 나중에 다루겠습니다. 필요하신 분들은 [링크1](https://spdk.io/doc/app_overview.html) [링크2](https://spdk.io/doc/jsonrpc.html)를 참고하세요!
일단 rpc 통신을 위해 소켓을 생성해야 합니다. 동작 여부를 확인하기 위해 소켓 프로세스는 포그라운드로 실행하겠습니다. 별도의 터미널을 띄우고 `build/bin/spdk_tgt`를 실행합니다. [참고](https://github.com/spdk/spdk/issues/295)
TODO : spdk_tgt에 대한 설명 추가

  * 새로운 터미널에서 수행

  ```
  [root@localhost spdk]# build/bin/spdk_tgt
  [2022-01-13 03:09:42.140847] Starting SPDK v22.01-pre git sha1 ed8be4ad0 / DPDK 21.08.0 initialization...
  [2022-01-13 03:09:42.141026] [ DPDK EAL parameters: [2022-01-13 03:09:42.141060] spdk_tgt [2022-01-13 03:09:42.141086] --no-shconf [2022-01-13 03:09:42.141108] -c 0x1 [2022-01-13 03:09:42.141142] --log-level=lib.eal:6 [2022-01-13 03:09:42.141189] --log-level=lib.cryptodev:5 [2022-01-13 03:09:42.141217] --log-level=user1:6 [2022-01-13 03:09:42.141241] --iova-mode=pa [2022-01-13 03:09:42.141265] --base-virtaddr=0x200000000000 [2022-01-13 03:09:42.141293] --match-allocations [2022-01-13 03:09:42.141316] --file-prefix=spdk_pid9976 [2022-01-13 03:09:42.141339] ]
  EAL: No available 1048576 kB hugepages reported
  EAL: No free 2048 kB hugepages reported on node 1
  TELEMETRY: No legacy callbacks, legacy socket not created
  [2022-01-13 03:09:42.223467] app.c: 543:spdk_app_start: *NOTICE*: Total cores available: 1
  [2022-01-13 03:09:42.354606] reactor.c: 943:reactor_run: *NOTICE*: Reactor started on core 0
  [2022-01-13 03:09:42.354674] accel_engine.c:1012:spdk_accel_engine_initialize: *NOTICE*: Accel engine initialized to use software engine.
  ```

이어서 `spdk_tgt`를 수행한 터미널이 아닌 다른 터미널에서 소켓이 생성되었는지 확인합니다. 모두 아시다시피 리눅스는 프로세스간의 통신을 파일 형태의 소켓으로 관리합니다. spdk의 rpc를 위한 소켓 파일은 `/var/tmp/spdk.sock`에서 확인할 수 있습니다.

  ```
  [root@localhost spdk]# ls -l /var/tmp/spdk.sock
  srwxr-xr-x 1 root root 0 Apr  8 19:36 /var/tmp/spdk.sock
  [root@localhost spdk]# lsof -U | grep 'spdk.sock'
  reactor_0  49063           root  373u  unix 0xffff9a31531df2c0      0t0 656974096 /var/tmp/spdk.sock
  [root@localhost spdk]# file /var/tmp/spdk.sock
  /var/tmp/spdk.sock: socket
  ```

  * 참고
    - https://spdk.io/doc/bdev.html
    - https://github.com/spdk/spdk/issues/295

### NVMe 컨트롤러 등록

자, SPDK 실습을 위한 환경 구성이 완료되었습니다. 지금부터는 SPDK에서 제공하는 bdev 목록에서 몇 개의 기능을 사용해보도록 하겠습니다. 먼저 SPDK에서 NVMe SSD의 컨트롤러 정보를 불러오는 방법입니다. 일반적으로 리눅스에서 NVMe SSD를 제어할 때 `nvme` 명령을 사용합니다. `nvme` 명령은 NVMe github의 nvme-cli 코드로 관리되며 NVMe의 최신 스펙에 맞춰서 기속적으로 개발되고 있습니다. `nvme` 명령으로는 NVMe SSD의 다양한 설정을 수행할 수 있습니다. 2019년도 당시, 국제 스토리지 성능 평가를 수행하는 SPC 협회의 SPC-1 성능 테스트를 수행할 때 `nvme` 명령으로 삼성과 인텔 NVMe SSD의 성능 최적화를 수행했었습니다(~~[당시 세계 성능 5위](https://www.etnews.com/20190102000138), 깨알 자랑~~). 그만큼 `nvme` 명령은 NVMe SSD에 강력한 기능을 제공합니다만, SPDK로 오너쉽을 넘긴 이상 `nvme` 명령으로 더이상 NVMe SSD를 제어할 수 없습니다. 띄옹??? 한번 확인해볼까요?

  ```
  [root@localhost spdk]# nvme list
  <no output message>
  ```

홀리 x, 그러면 NVMe SSD의 컨트롤러 정보를 불러오지 못하는가? 아닙니다. NVMe SSD 제조사는 NVM Express 협회에서 제공하는 표준 스펙을 따라야 합니다. 물론 과거에도 FusionIO 와 같은 낸드 플래시와 PCIe 인터페이스를 접목한 PCIe SSD(유사 NVMe) 제품들이 있었습니다. 다만, 워낙 고가였고 제조사마다 서로 다른 스펙으로 개발되었기 때문에 일반 PC급 시장보다 서버시장에서 주로 사용되었습니다. 당시 PCIe SSD 는 별다른 표준이 없었기에 제조사마다 서로 다른 스펙을 가졌었고, 대부분의 기술이 공개되지 않아 소프트웨어 계층에서는 적극적인 활용이 어려웠습니다. 이러한 문제가 직면되어 다른 진영에서는 표준화 작업을 진행하였고, 인텔이 주도한 PCIe SSD 표준화 협회가 NVM Express, 여기서 등장한 표준이 NVMe & NVMe-oF specification 입니다. (짝짝짝!!)
    
음... 잠깐 샛길로 빠졌군요. 다시 돌아와서! 어쨌던 공개된 NVMe 스펙을 통해서 SPDK에서도 `nvme` 명령과 유사한 작업을 수행할 수 있습니다. 한번 볼까요? 먼저 `spdk_tgt`이 동작하고 있어야 하며, `spdk_tgt`이 수행되지 않은 다른 터미널에서 아래 명령을 수행합니다. 먼저 현재 장비에 설치되어 있는 NVMe SSD 장치의 PCIe 번홀를 확인합니다.

  ```
  [root@localhost spdk]# lspci | grep -i ssd
  3b:00.0 Non-Volatile memory controller: Intel Corporation Optane SSD 900P Series
  ```

아 좋습니다. 인텔의 Optane SSD 900P 시리즈 제품이 확인되네요. 연구소에 이런 제품들이 사무용 마우스보다 훨씬 많습니다. (현재 120만원, 출시 당시 가격 ㅎㄷㄷ) `3b:00.0`을 확인했으니 컨트롤러를 SPDK에 연결해봅니다. 이때, RPC 통신을 위해서 모든 작업은 `scripts/rpc.py`로 수행되어야 합니다. 실행할 작업은 `bdev_nvme_attach_controller` 입니다. 연결할 컨트롤러의 이름은 `NVMe`, 연결 방식은 `pcie`로 하겠습니다.

  ```
  [root@localhost spdk]# scripts/rpc.py bdev_nvme_attach_controller -b NVMe0 -t pcie -a 0000:3b:00.0
  NVMe0n1
  ```

오 뭔가 명령이 잘 수행된 느낌입니다. SPDK에 연결된 컨트롤러 정보를 불러오겠습니다.

  ```
  [root@localhost spdk]# scripts/rpc.py bdev_nvme_get_controllers
  [
    {
      "name": "NVMe0",
      "trid": {
        "trtype": "PCIe",
        "traddr": "0000:3b:00.0"
      },
      "host": {
        "nqn": "nqn.2014-08.org.nvmexpress:uuid:2b4d86b5-b34a-4983-9830-2978727acb4a",
        "addr": "",
        "svcid": ""
      }
    }
  ]
  ```

짝짝짝. 잘 연결되어 있습니다. 좋습니다. 반대로 연결을 해제하고 싶으면 `bdev_nvme_detach_controller`를 실행하시면 됩니다.

  ```
  [root@localhost spdk]# scripts/rpc.py bdev_nvme_detach_controller NVMe0
  [root@localhost spdk]# scripts/rpc.py bdev_nvme_get_controllers
  []
  ```

이외에도 현재 SPDK에서 제공하는 nvme와 관련된 여러 기능들을 사용할 수 있습니다.

  ```
  [root@localhost spdk]# # scripts/rpc.py | grep nvme
      bdev_nvme_set_options (set_bdev_nvme_options)
                            Set options for the bdev nvme type. This is startup
      bdev_nvme_set_hotplug (set_bdev_nvme_hotplug)
                            Set hotplug options for bdev nvme type.
      bdev_nvme_attach_controller (construct_nvme_bdev)
                            Add bdevs with nvme backend
      bdev_nvme_get_controllers (get_nvme_controllers)
      bdev_nvme_detach_controller (delete_nvme_controller)
      bdev_nvme_reset_controller
      bdev_nvme_cuse_register
      bdev_nvme_cuse_unregister
      bdev_nvme_apply_firmware (apply_firmware)
      bdev_nvme_get_transport_statistics
                            Get bdev_nvme poll group transport statistics
      bdev_nvme_get_controller_health_info
      bdev_nvme_opal_init
      bdev_nvme_opal_revert
      bdev_nvme_send_cmd (send_nvme_cmd)
  ```

OK 좋습니다. 그런데 최적화 같은 제조사가 제공하는 컨트롤러의 여러 기능들을 변경하고 싶은데, SPDK로 등록하면 어떻게 제어해야하나? 방법이 있습니다. 먼저 PCIe configuration register format(아래 그림1)을 보시고, BAR(Base Address Registers)에 등록된 NVMe controller register format(아래 그림2)을 확인한 다음에, 얻으려는 정보가 맵핑된 메모리의 위치를 찾아서 `bdev_nvme_send_cmd` 기능을 사용해서 NVMe 컨트롤러에 명령을 보내면 알려줍니다.

![Alt text](/assets/pci_header.png) 참고 : NVMe Spec. version 1.4b document
<center>그림 1. PCIe configuration register format</center>

![Alt text](/assets/nvme_register.png)
<center>그림 2. NVMe controller register format</center>

점점 깊어지고 실습하기 싫어지네요. 하드웨어 잘 아는 개발자들이 친절하게 NVMe 스펙 참고해서 일반인이 편히 사용하기 위해서(~~자기들도 편하려고..~~) nvme-cli를 만들었는데, 그걸 사용하지 못하니까 답답합니다. 다행히도 SPDK에서는 `nvme` 명령처럼 기존 명령이나 또는 어플리케이션에서 장치와 직접 통신할 수 있는 방법을 제공합니다. 바로 문자 드라이버 등록입니다.

### 문자 드라이버 등록

리눅스에서는 모든 것을 파일로 관리합니다. 우리가 컴퓨터에 장치를 연결하면 리눅스 커널은 장치를 인식해서 알맞은 드라이버를 호출하고 `/dev` 하위에 파일을 생성합니다. 우리가 사용하는 하드디스크도 ATA 인터페이스 기반의 SCSI 또는 SATA 드라이버로 연결되어 `/dev` 하위에 `hda, hdb, sda, sdb`등으로 보여지는 것입니다. NVMe SSD도 같습니다. 커널은 NVMe SSD가 인식되면 NVMe 드라이버를 커널에서 불러와 `/dev` 하위에 `nvme0, nvme1`과 같이 보여줍니다. `nvme0`뒤에 `n1, n2`와 같은 것은 namespace로 NVMe SSD에서 논리적인 분리된 저장 공간의 번호를 뜻합니다. 파티션 또는 논리 볼륨과 비슷한 개념입니다.

  * 다음으로 연결한 NVMe 컨트롤러에 namespace를 문자 드라이버로 등록하는 방법이다.
  * 문자 드라이버는 cuse라는 라이브러리를 통해 사용한다.
  * 따라서 앞서 spdk 환경을 구성할 때 `./configure` 명령에 `--with-nvme-cuse` 옵션을 붙이고 다시 빌드(`make`)를 수행한다. `spdk_tgt`도 내리고 수행한다.
  ```
  [root@localhost spdk]# ./configure --with-nvme-cuse
  [root@localhost spdk]# make
  [root@localhost spdk]# scripts/setup.sh
  [root@localhost spdk]# modprobe cuse
  [root@localhost spdk]# lsmod | grep cuse
  cuse                   13274  0
  fuse                  100350  4 cuse
  [root@localhost spdk]# build/bin/spdk_tgt
  ...
  (다른 터미널)
  [root@localhost spdk]# scripts/rpc.py bdev_nvme_attach_controller -b NVMe0 -t PCIe -a 0000:3b:00.0
  NVMe0n1
  ```
  * 소켓까지 다시 올렸으면 spdk와 연결된 컨트롤러를 문자 드라이버로 등록한다.
  ```
  [root@localhost spdk]# scripts/rpc.py bdev_nvme_cuse_register -n NVMe0
  [root@localhost spdk]# ls /dev/spdk/
  nvme0  nvme0n1
  [root@localhost spdk]# nvme id-ctrl /dev/spdk/nvme0 -H
  NVME Identify Controller:
  vid       : 0x8086
  ssvid     : 0x8086
  sn        : PHMB7435004J280CGN
  mn        : INTEL SSDPED1D280GA
  fr        : E2010325
  rab       : 0
  ieee      : 5cd2e4
  cmic      : 0
  [2:2] : 0     PCI
  [1:1] : 0     Single Controller
  [0:0] : 0     Single Port
  ...
  [root@localhost spdk]# scripts/rpc.py bdev_get_bdevs
  [
    {
    "name": "NVMe0n1",
      "aliases": [],
      "product_name": "NVMe disk",
      "block_size": 512,
      "num_blocks": 547002288,
      "uuid": "0b1f1ff5-4bb6-4fea-b436-0359ad12f7ee",
      "assigned_rate_limits": {
        "rw_ios_per_sec": 0,
        "rw_mbytes_per_sec": 0,
        "r_mbytes_per_sec": 0,
        "w_mbytes_per_sec": 0
      },
      "claimed": true,
      "zoned": false,
      "supported_io_types": {
        "read": true,
        "write": true,
        "unmap": true,
        "write_zeroes": true,
        "flush": true,
        "reset": true,
        "nvme_admin": true,
        "nvme_io": true
      },
      "driver_specific": {
        "nvme": {
          "pci_address": "0000:3b:00.0",
          "trid": {
            "trtype": "PCIe",
            "traddr": "0000:3b:00.0"
          },
          "cuse_device": "spdk/nvme0n1",
          "ctrlr_data": {
            "vendor_id": "0x8086",
            "model_number": "INTEL SSDPED1D280GA",
            "serial_number": "PHMB7435004J280CGN",
            "firmware_revision": "E2010325",
            "oacs": {
              "security": 1,
              "format": 1,
              "firmware": 1,
              "ns_manage": 0
            }
          },
          "vs": {
            "nvme_version": "1.0"
          },
          "ns_data": {
            "id": 1
          },
          "security": {
            "opal": false
          }
        }
      }
    }
  ]
  ```
  * NVMe 컨트롤러 해제와 마찬가지로 문자 드라이버 등록을 해제하려면 아래와 같다.
  ```
  [root@localhost spdk]# scripts/rpc.py bdev_nvme_cuse_unregister -n NVMe0
  ```
  * 참고
    - https://spdk.io/doc/bdev.html
    - https://spdk.io/doc/nvme.html

### lvol 생성

  * spdk는 lvol이라고 불리는 논리 볼륨을 제공한다.
  * 이를 위해서는 연결된 NVMe 컨트롤러에 lvol을 생성할 논리 볼륨 저장소를 지정해야한다. 뭐랄까.. VG라고 할까?
  ```
  [root@localhost spdk]# scripts/rpc.py bdev_lvol_create_lvstore NVMe0n1 lvs
  1818d45a-3a05-42c9-bbb2-9229cc25ac49
  ```
  [root@localhost spdk]# scripts/rpc.py bdev_get_bdevs
  [root@localhost spdk]# scripts/rpc.py bdev_lvol_get_lvstores
  [
    {
      "uuid": "1818d45a-3a05-42c9-bbb2-9229cc25ac49",
        "name": "lvs",
        "base_bdev": "NVMe0n1",
        "total_data_clusters": 66706,
        "free_clusters": 66706,
        "block_size": 512,
        "cluster_size": 4194304
    }
  ]
  ```
  * 마찬가지로 삭제는 아래와 같다.
  [root@localhost spdk]# scripts/rpc.py bdev_lvol_delete_lvstore -l lvs
  [root@localhost spdk]# scripts/rpc.py bdev_lvol_get_lvstores
  []
  ```
  * 로컬 볼륨 저장소를 생성했으면 로컬 볼륨(lvol)를 생성해보자.
  ```
  [root@localhost spdk]# scripts/rpc.py bdev_lvol_create lvol1 25 -l lvs
  8eaafae0-80cb-45f8-beb6-65ae4f73e73a
  [root@localhost spdk]# scripts/rpc.py bdev_get_bdevs
  [
    {...},
    {
      "name": "8eaafae0-80cb-45f8-beb6-65ae4f73e73a",
      "aliases": [
        "lvs/lvol1"
      ],
      "product_name": "Logical Volume",
      "block_size": 512,
      "num_blocks": 57344,
      "uuid": "8eaafae0-80cb-45f8-beb6-65ae4f73e73a",
      "assigned_rate_limits": {
        "rw_ios_per_sec": 0,
        "rw_mbytes_per_sec": 0,
        "r_mbytes_per_sec": 0,
        "w_mbytes_per_sec": 0
      },
      "claimed": false,
      "zoned": false,
      "supported_io_types": {
        "read": true,
        "write": true,
        "unmap": true,
        "write_zeroes": true,
        "flush": false,
        "reset": true,
        "nvme_admin": false,
        "nvme_io": false
      },
      "driver_specific": {
        "lvol": {
          "lvol_store_uuid": "a65efd50-07df-415e-852f-7f9725d269cd",
          "base_bdev": "NVMe0n1",
          "thin_provision": false,
          "snapshot": false,
          "clone": false
        }
      }
    }
  ]
  ```
  * 삭제도 마찬가지로 아래와 같다.
  ```
  [root@localhost spdk]# scripts/rpc.py bdev_lvol_delete lvs/lvol1
  ```
  * 이외에도 다양한 기능들을 지원한다.
    - bdev_lvol_snapshot
    - bdev_lvol_clone
    - bdev_lvol_rename
    - bdev_lvol_resize
    - bdev_lvol_set_read_only
    - bdev_lvol_inflate
    - bdev_lvol_decouple_parent
  * 참고
    - https://spdk.io/doc/bdev.html
    - https://spdk.io/doc/logical_volumes.html

### RAID 0 생성

  * ...
  ```
  [root@localhost spdk]# scripts/rpc.py bdev_raid_create -n raid0 -z 64 -r 0 -b "lvol1 lvol2 lvol3 lvol4"
  [root@localhost spdk]# scripts/rpc.py bdev_raid_get_bdevs all
  raid0
  ```

### RAID 5 생성

  * ...
  ```
  [root@localhost spdk]# ./configure --with-raid5
  [root@localhost spdk]# make
  [root@localhost spdk]# ./build/bin/spdk_tgt &
  [root@localhost spdk]# scripts/rpc.py bdev_raid_create -n raid5 -z 64 -r 5 -b "lvol1 lvol2 lvol3 lvol4"
  [root@localhost spdk]# scripts/rpc.py bdev_raid_get_bdevs all
  raid5
  [root@localhost spdk]# cd module/bdev/raid
  [root@localhost raid]# ls -lh
  [root@localhost raid]# ls -lh
  total 464K
  -rw-r--r-- 1 root root  42K Nov  1 06:27 bdev_raid.c
  -rw-r--r-- 1 root root 1.5K Jan 21 01:34 bdev_raid.d
  -rw-r--r-- 1 root root 9.9K Nov  1 06:27 bdev_raid.h
  -rw-r--r-- 1 root root 153K Jan 21 01:34 bdev_raid.o
  -rw-r--r-- 1 root root  13K Nov  1 06:27 bdev_raid_rpc.c
  -rw-r--r-- 1 root root 1.7K Jan 21 01:34 bdev_raid_rpc.d
  -rw-r--r-- 1 root root  75K Jan 21 01:34 bdev_raid_rpc.o
  -rw-r--r-- 1 root root 2.0K Nov  1 06:27 Makefile
  -rw-r--r-- 1 root root  13K Nov  1 06:27 raid0.c
  -rw-r--r-- 1 root root 1.5K Jan 21 01:34 raid0.d
  -rw-r--r-- 1 root root  72K Jan 21 01:34 raid0.o
  -rw-r--r-- 1 root root 3.6K Nov  1 06:27 raid5.c
  -rw-r--r-- 1 root root 1.5K Jan 21 01:34 raid5.d
  -rw-r--r-- 1 root root  45K Jan 21 01:34 raid5.o
  ```

&nbsp;

## SPDK 성능 측정

### 테스트 환경

### bdevperf 테스트

  * spdk에서는 자체적으로 `bdevperf`와 `fio` 성능 테스트 툴을 제공한다. (당연한것이 호환되는게 없음..)

### bdevperf

  * `bdevperf`는 `<path to spdk repo>/test/bdev/bdevperf` 디렉토리에 존재하며 간단하게 `test_config.sh`를 수행하여 테스트를 수행해볼 수 있다.
  ```
  [root@localhost spdk]# cd test/bdev/bdevperf`
  [root@localhost bdevperf]# ls -l
  -rwxr-xr-x 1 root root 7740256 Jan 13 05:22 bdevperf
  -rw-r--r-- 1 root root   56826 Nov  1 06:27 bdevperf.c
  -rw-r--r-- 1 root root    1840 Jan 13 05:22 bdevperf.d
  -rw-r--r-- 1 root root  227480 Jan 13 05:22 bdevperf.o
  -rwxr-xr-x 1 root root    2910 Nov  1 06:27 bdevperf.py
  -rw-r--r-- 1 root root     587 Nov  1 06:27 common.sh
  -rw-r--r-- 1 root root     473 Nov  1 06:27 conf.json
  -rw-r--r-- 1 root root    2017 Nov  1 06:27 Makefile
  -rwxr-xr-x 1 root root    1257 Nov  1 06:27 test_config.sh
  [root@localhost bdevperf]# ./test_config.sh
  ...
  =============================================================
  Total                       : 2228736.00 IOPS    2176.50 MiB/s'
  22:44:02      -- bdevperf/common.sh@28 -- # grep -oE '[0-9]+'
  22:44:02       -- ./test_config.sh@39 -- # [[ 4 == \4 ]]
  22:44:02       -- ./test_config.sh@40 -- # cleanup
  22:44:02       -- bdevperf/common.sh@32 -- # rm -f /root/spdk/test/bdev/bdevperf/test.conf
  22:44:02       -- ./test_config.sh@41 -- # trap - SIGINT SIGTERM EXIT
  ```
  * 아 이렇게 동작하구나~ 그러면 원하는데로 돌려보자, 옵션은 `./bdevperf --help`로 찾아볼 수 있다.
  * 그 전에, 일반적으로 벤치마킹 툴을 사용해봤으면 알겠지만, 성능을 측정할 대상(경로 또는 장치)을 지정해야하는데 spdk는 경로가 존재하지 않기 때문에 테스트할 대상을 지정할 설정 파일이 필요하다.
  * 샘플로 `conf.json`을 보면 json 타입으로 어떤 장치인지 지정되어 있는것을 확인할 수 있다.
  ```
  [root@localhost bdevperf]# cat conf.json
  {
    "subsystems": [
    {
      "subsystem": "bdev",
      "config": [
      {
        "method": "bdev_malloc_create",
        "params": {
          "name": "Malloc0",
          "num_blocks": 102400,
          "block_size": 512
        }
      },
      {
        "method": "bdev_malloc_create",
        "params": {
          "name": "Malloc1",
          "num_blocks": 102400,
          "block_size": 512
        }
      }
      ]
    }
    ]
  }
```
    - 위 내용을 확인해보면 각각 50MiB(512 * 102400) 용량을 갖는 Malloc1과 Malloc2를 메모리에 생성하겠다는 것이다.  * 그렇다면 128 iodepth를 가지며, 4KiB 블록 크기로 읽기 테스트를 300초 동안 수행해보자
    ```
    [root@localhost bdevperf]# ./bdevperf -t 300 -c ./conf.json -q 128 -o 4096 -w read
    [2022-01-13 22:47:33.489389] Starting SPDK v22.01-pre git sha1 ed8be4ad0 / DPDK 21.08.0 initialization...
    [2022-01-13 22:47:33.489561] [ DPDK EAL parameters: [2022-01-13 22:47:33.489591] bdevperf [2022-01-13 22:47:33.489612] --no-shconf [2022-01-13 22:47:33.489635] -c 0x1 [2022-01-13 22:47:33.489656] --log-level=lib.eal:6 [2022-01-13 22:47:33.489676] --log-level=lib.cryptodev:5 [2022-01-13 22:47:33.489697] --log-level=user1:6 [2022-01-13 22:47:33.489718] --iova-mode=pa [2022-01-13 22:47:33.489739] --base-virtaddr=0x200000000000 [2022-01-13 22:47:33.489761] --match-allocations [2022-01-13 22:47:33.489781] --file-prefix=spdk_pid174830 [2022-01-13 22:47:33.489804] ]
    EAL: No available 1048576 kB hugepages reported
    EAL: No free 2048 kB hugepages reported on node 1
    TELEMETRY: No legacy callbacks, legacy socket not created
    [2022-01-13 22:47:33.593973] app.c: 543:spdk_app_start: *NOTICE*: Total cores available: 1
    [2022-01-13 22:47:33.880832] reactor.c: 943:reactor_run: *NOTICE*: Reactor started on core 0
    [2022-01-13 22:47:33.881331] accel_engine.c:1012:spdk_accel_engine_initialize: *NOTICE*: Accel engine initialized to use software engine.
    Running I/O for 300 seconds...
    Job: Malloc0 (Core Mask 0x1)
    Malloc0             :  407177.81 IOPS    1590.54 MiB/s
    Job: Malloc1 (Core Mask 0x1)
    Malloc1             :  407177.81 IOPS    1590.54 MiB/s
    =============================================================
    Total                       :  814355.63 IOPS    3181.08 MiB/s
    ```
    - 결과처럼 Malloc0과 Malloc1에 테스트를 수행한 것을 알 수 있다.
  * 다음으로 메모리로 생성한 장치가 아닌 실제 NVMe SSD의 spdk 드라이버 성능을 측정해보자
  * 마찬가지로 conf 파일을 설정해야하는데, 이는 `scripts/get_nvme.sh` 스크립트를 이용하여 NVMe 설정 파일을 생성할 수 있다.
  ```
  [root@localhost bdevperf]# /root/spdk/scripts/gen_nvme.sh --json-with-subsystems | jq . > nvme.json
  [root@localhost bdevperf]# cat nvme.json
  {
    "subsystems": [
    {
      "subsystem": "bdev",
      "config": [
      {
        "method": "bdev_nvme_attach_controller",
        "params": {
          "trtype": "PCIe",
          "name": "Nvme0",
          "traddr": "0000:3b:00.0"
        }
      }
      ]
    }
    ]
  }
  ```
  * NVMe 장치에 bdevperf를 수행해보자, 옵션은 MallocX와 동일하지만 설정 파일이 변경되었으니 -c 옵션에 설정 경로만 다르게 해준다.
  ```
  [root@localhost bdevperf]# ./bdevperf -t 300 -c ./nvme.json -q 128 -o 4096 -w read
  [2022-01-13 23:15:52.588048] Starting SPDK v22.01-pre git sha1 ed8be4ad0 / DPDK 21.08.0 initialization...
  [2022-01-13 23:15:52.588245] [ DPDK EAL parameters: [2022-01-13 23:15:52.588276] bdevperf [2022-01-13 23:15:52.588297] --no-shconf [2022-01-13 23:15:52.588319] -c 0x1 [2022-01-13 23:15:52.588354] --log-level=lib.eal:6 [2022-01-13 23:15:52.588375] --log-level=lib.cryptodev:5 [2022-01-13 23:15:52.588396] --log-level=user1:6 [2022-01-13 23:15:52.588417] --iova-mode=pa [2022-01-13 23:15:52.588439] --base-virtaddr=0x200000000000 [2022-01-13 23:15:52.588460] --match-allocations [2022-01-13 23:15:52.588481] --file-prefix=spdk_pid241533 [2022-01-13 23:15:52.588503] ]
  EAL: No available 1048576 kB hugepages reported
  EAL: No free 2048 kB hugepages reported on node 1
  TELEMETRY: No legacy callbacks, legacy socket not created
  [2022-01-13 23:15:52.683909] app.c: 543:spdk_app_start: *NOTICE*: Total cores available: 1
  [2022-01-13 23:15:52.951868] reactor.c: 943:reactor_run: *NOTICE*: Reactor started on core 0
  [2022-01-13 23:15:52.952347] accel_engine.c:1012:spdk_accel_engine_initialize: *NOTICE*: Accel engine initialized to use software engine.
  Running I/O for 300 seconds...
  Job: Nvme0n1 (Core Mask 0x1)
  Nvme0n1             :  334248.13 IOPS    1305.66 MiB/s
  =============================================================
  Total                       :  334248.13 IOPS    1305.66 MiB/s
  ```

### FIO 테스트

  * 'fio에 대한 간단한 설명 추가'
  * fio 테스트를 위해서는 fio 소스 코드를 빌드해야 한다. 관련 내용은 [여기](https://github.com/spdk/spdk/tree/master/examples/nvme/fio_plugin)를 참고해서 설치하면 된다.
  ```
  [root@localhost ~]# git clone https://github.com/axboe/fio
  [root@localhost ~]# cd fio
  [root@localhost fio]# make
  [error]
  ```
    - gcc 버전이 낮다.. [여기](https://m.blog.naver.com/alice_k106/221019680668)를 참고해서 올리자..
  * 다시 시작.. 성공!
  ```
  LINK t/read-to-pipe-async
  LINK t/fio-btrace2fio
  LINK t/io_uring
  [root@localhost fio]# ls -l fio
  -rwxr-xr-x 1 root root 6400472 Jan 13 23:45 fio
  [root@localhost fio]# cd ~/spdk
  [root@localhost spdk]# ./configure --with-fio=/root/fio
  Notice: ISA-L, compression & crypto require NASM version 2.14 or newer. Turning off default ISA-L and crypto features.
  Using default SPDK env in /root/spdk/lib/env_dpdk
  Using default DPDK in /root/spdk/dpdk/build
  Creating mk/config.mk...done.
  Creating mk/cc.flags.mk...done.
  [root@localhost spdk]# make 
  ...
  CXX test/cpp_headers/string.o
  CXX test/cpp_headers/gpt_spec.o
  CXX test/cpp_headers/nvme_ocssd.o
  LINK dif_ut
  LINK ftl_wptr_ut
  LINK ftl_io_ut
  [root@localhost spdk]# ls build/fio
  total 12852
  -rwxr-xr-x 1 root root 8665272 Jan 13 23:49 spdk_bdev
  -rwxr-xr-x 1 root root 4490272 Jan 13 23:49 spdk_nvme
  ```
  * fio 를 실행할 때에는 spdk의 플러그인을 사용하려면 `LD_PRELOAD` 매개변수를 통해 spdk의 경로를 입력해야한다.
  * 그렇다면 한번 실행해보자, 먼저 bdevperf와 동일하게 NVMe 장치 설정을 가져온다.
  ```
  [root@localhost spdk]# cd examples/bdev/fio_plugin
  [root@localhost fio_plugin]# /root/spdk/scripts/gen_nvme.sh --json-with-subsystems | jq . > nvme.json
  [root@localhost fio_plugin]# cat nvme.json
  {
    "subsystems": [
    {
      "subsystem": "bdev",
        "config": [
        {
          "method": "bdev_nvme_attach_controller",
          "params": {
            "trtype": "PCIe",
            "name": "Nvme0",
            "traddr": "0000:3b:00.0"
          }
        }
        ]
    }
    ]
  }
  ```
  * 이 떄, fio config에 `nvme.json`을 설정하면 성능 측정 전에 자동으로 SPDK에 NVMe 컨트롤러를 연결한다. 따라서 기존에 SPDK에 attach한 NVMe 컨트롤러가 있다면 해제해야한다.
  ```
  [root@localhost fio_plugin]# scripts/rpc.py bdev_nvme_detach_controller NVMe0
  [root@localhost fio_plugin]# scripts/rpc.py bdev_nvme_get_controllers
  []
  ```
  * fio 테스트 옵션은 [spdk performance report](https://ci.spdk.io/download/performance-reports/SPDK_nvme_bdev_perf_report_2110.pdf)의 'Test Case 1'의 설정을 참고했다.
  ```
  [root@localhost fio_plugin]# cat run_fio.fio
  [global]
  ioengine=/root/spdk/build/fio/spdk_bdev
  spdk_json_conf=/root/spdk/examples/bdev/fio_plugin/nvme.json

  gtod_reduce=1
  direct=1
  thread=1
  norandommap=1
  time_based=1
  ramp_time=60s
  runtime=300s
  rw=read
  bs=4k
  numjobs=1

  [filename0]
  filename=Nvme0n1
  iodepth=128

  [root@localhost fio_plugin]# /root/fio/fio ./run_fio.fio
  filename0: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=spdk_bdev, iodepth=128
  fio-3.29-7-g01686
  Starting 1 thread
  [2022-01-20 22:49:33.573673] Starting SPDK v22.01-pre git sha1 ed8be4ad0 / DPDK 21.08.0 initialization...
  [2022-01-20 22:49:33.573890] [ DPDK EAL parameters: [2022-01-20 22:49:33.573922] fio [2022-01-20 22:49:33.573944] --no-shconf [2022-01-20 22:49:33.573965] -c 0x1 [2022-01-20 22:49:33.573986] --log-level=lib.eal:6 [2022-01-20 22:49:33.574007] --log-level=lib.cryptodev:5 [2022-01-20 22:49:33.574027] --log-level=user1:6 [2022-01-20 22:49:33.574062] --iova-mode=pa [2022-01-20 22:49:33.574082] --base-virtaddr=0x200000000000 [2022-01-20 22:49:33.574103] --match-allocations [2022-01-20 22:49:33.574124] --file-prefix=spdk_pid269971 [2022-01-20 22:49:33.574145] ]
  EAL: No available 1048576 kB hugepages reported
  EAL: No free 2048 kB hugepages reported on node 1
  TELEMETRY: No legacy callbacks, legacy socket not created
  [2022-01-20 22:49:33.707015] accel_engine.c:1012:spdk_accel_engine_initialize: *NOTICE*: Accel engine initialized to use software engine.
  Jobs: 1 (f=1): [R(1)][100.0%][r=2602MiB/s][r=666k IOPS][eta 00m:00s]
  filename0: (groupid=0, jobs=1): err= 0: pid=270034: Thu Jan 20 22:55:33 2022
    read: IOPS=666k, BW=2603MiB/s (2730MB/s)(763GiB/300001msec)
      bw (  MiB/s): min= 2567, max= 2614, per=100.00%, avg=2604.31, stdev= 7.14, samples=600
      iops        : min=657376, max=669316, avg=666702.32, stdev=1828.62, samples=600
    cpu          : usr=100.00%, sys=0.00%, ctx=724, majf=0, minf=139
    IO depths    : 1=0.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=100.0%
      submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
      complete  : 0=0.0%, 4=100.0%, 8=0.1%, 16=0.1%, 32=0.1%, 64=0.1%, >=64=0.1%
      issued rwts: total=199938792,0,0,0 short=0,0,0,0 dropped=0,0,0,0
      latency   : target=0, window=0, percentile=100.00%, depth=128

  Run status group 0 (all jobs):
    READ: bw=2603MiB/s (2730MB/s), 2603MiB/s-2603MiB/s (2730MB/s-2730MB/s), io=763GiB (819GB), run=300001-300001msec
  ```
  * 참고
    - https://www.intel.com/content/www/us/en/developer/articles/technical/evaluate-performance-for-storage-performance-development-kit-spdk-based-nvme-ssd.html
    - https://github.com/spdk/spdk/issues/1104

### 실시간 모니터링 방법

&nbsp;

마치며
-----

끝내는 말(You Died)

&nbsp;

각주
---

[^1]: vfio
[^2]: uio
[^3]: rpc
